{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17e3d3b",
   "metadata": {
    "papermill": {
     "duration": 0.015872,
     "end_time": "2025-08-17T05:00:44.567133",
     "exception": false,
     "start_time": "2025-08-17T05:00:44.551261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    " # ✈️ FlightRank 2025: Aeroclub RecSys Cup\n",
    "\n",
    " **Personalized Flight Recommendations for Business Travelers**\n",
    " ---------------------------------------------------------------------------------\n",
    " \n",
    " **Title:** FlightRank 2025 – Baseline Modeling Pipeline\n",
    " \n",
    " **Author**: ISHITA\n",
    " \n",
    " **Goal**: Build a modular baseline pipeline for user-flight interaction prediction using LightGBM\n",
    " \n",
    " **Notebook Highlights**:\n",
    " - Clean data loading and metadata integration\n",
    " - Feature engineering for user behavior and flight characteristics\n",
    " - Cross-validated LightGBM baseline\n",
    " - Submission-ready predictions\n",
    " \n",
    " Before optimizing for Hitrate@3, this notebook ensures a clean, reproducible foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6dbe51",
   "metadata": {
    "papermill": {
     "duration": 0.011753,
     "end_time": "2025-08-17T05:00:44.591881",
     "exception": false,
     "start_time": "2025-08-17T05:00:44.580128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ![FlightRank 2025 Cover](data:image/jpeg;base64,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)\n",
    "\n",
    "\n",
    "**A data-driven journey into flight recommendation systems. Presented by Aeroclub for the RecSys Cup 2025, this visual blends aviation with algorithmic precision—featuring a stylized aircraft built from numerical data points, set against a sleek grid backdrop. Innovation takes.**\n",
    "\n",
    "\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba3c90",
   "metadata": {
    "id": "lwReq34lxth4",
    "papermill": {
     "duration": 0.012049,
     "end_time": "2025-08-17T05:00:44.616481",
     "exception": false,
     "start_time": "2025-08-17T05:00:44.604432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**📝 1. Introduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5feb3171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:00:44.645134Z",
     "iopub.status.busy": "2025-08-17T05:00:44.644861Z",
     "iopub.status.idle": "2025-08-17T05:01:25.284255Z",
     "shell.execute_reply": "2025-08-17T05:01:25.278898Z"
    },
    "papermill": {
     "duration": 40.657822,
     "end_time": "2025-08-17T05:01:25.286685",
     "exception": false,
     "start_time": "2025-08-17T05:00:44.628863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment ===\n",
      "Running on Kaggle: True\n",
      "OUTPUT_DIR: /kaggle/working\n",
      "\n",
      "=== Scanning for files ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected train file: /kaggle/input/aeroclub-recsys-2025/train.parquet\n",
      "Detected test  file: /kaggle/input/aeroclub-recsys-2025/test.parquet\n",
      "Detected sample_submission file: /kaggle/input/aeroclub-recsys-2025/sample_submission.parquet\n",
      "Detected existing submission.csv (optional): None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- TRAIN HEAD (train.parquet) ----\n",
      "shape: (5, 126)\n",
      "columns (126): ['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber'] ...\n",
      "dtypes (first 15):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                               int64\n",
      "bySelf                                            bool\n",
      "companyID                                        int64\n",
      "corporateTariffCode                              Int64\n",
      "frequentFlyer                                   object\n",
      "nationality                                      Int64\n",
      "isAccess3D                                        bool\n",
      "isVip                                             bool\n",
      "legs0_arrivalAt                                 object\n",
      "legs0_departureAt                               object\n",
      "legs0_duration                                  object\n",
      "legs0_segments0_aircraft_code                   object\n",
      "legs0_segments0_arrivalTo_airport_city_iata     object\n",
      "legs0_segments0_arrivalTo_airport_iata          object\n",
      "legs0_segments0_baggageAllowance_quantity      float64\n",
      "dtype: object\n",
      "nulls (top 15):\n",
      "legs0_segments3_arrivalTo_airport_city_iata               5\n",
      "legs0_segments3_arrivalTo_airport_iata                    5\n",
      "legs0_segments3_baggageAllowance_quantity                 5\n",
      "legs0_segments2_operatingCarrier_code                     5\n",
      "legs0_segments2_flightNumber                              5\n",
      "legs0_segments2_marketingCarrier_code                     5\n",
      "legs0_segments3_departureFrom_airport_iata                5\n",
      "legs0_segments3_cabinClass                                5\n",
      "legs0_segments3_baggageAllowance_weightMeasurementType    5\n",
      "legs0_segments3_seatsAvailable                            5\n",
      "legs0_segments3_operatingCarrier_code                     5\n",
      "legs0_segments3_marketingCarrier_code                     5\n",
      "legs0_segments3_flightNumber                              5\n",
      "legs0_segments3_duration                                  5\n",
      "legs0_segments2_seatsAvailable                            5\n",
      "dtype: int64\n",
      "\n",
      "---- TEST  HEAD (test.parquet) ----\n",
      "shape: (5, 125)\n",
      "columns (125): ['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber'] ...\n",
      "dtypes (first 15):\n",
      "Id                                               int64\n",
      "bySelf                                            bool\n",
      "companyID                                        int64\n",
      "corporateTariffCode                              Int64\n",
      "frequentFlyer                                   object\n",
      "nationality                                      Int64\n",
      "isAccess3D                                        bool\n",
      "isVip                                             bool\n",
      "legs0_arrivalAt                                 object\n",
      "legs0_departureAt                               object\n",
      "legs0_duration                                  object\n",
      "legs0_segments0_aircraft_code                   object\n",
      "legs0_segments0_arrivalTo_airport_city_iata     object\n",
      "legs0_segments0_arrivalTo_airport_iata          object\n",
      "legs0_segments0_baggageAllowance_quantity      float64\n",
      "dtype: object\n",
      "nulls (top 15):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequentFlyer                                             5\n",
      "corporateTariffCode                                       5\n",
      "legs0_segments1_cabinClass                                5\n",
      "legs0_segments1_baggageAllowance_quantity                 5\n",
      "legs0_segments1_arrivalTo_airport_iata                    5\n",
      "legs0_segments1_baggageAllowance_weightMeasurementType    5\n",
      "legs0_segments1_aircraft_code                             5\n",
      "legs0_segments1_arrivalTo_airport_city_iata               5\n",
      "legs0_segments3_arrivalTo_airport_iata                    5\n",
      "legs0_segments3_arrivalTo_airport_city_iata               5\n",
      "legs0_segments3_aircraft_code                             5\n",
      "legs0_segments2_seatsAvailable                            5\n",
      "legs0_segments2_operatingCarrier_code                     5\n",
      "legs0_segments2_marketingCarrier_code                     5\n",
      "legs0_segments2_flightNumber                              5\n",
      "dtype: int64\n",
      "\n",
      "---- SAMPLE_SUBMISSION HEAD (sample_submission.parquet) ----\n",
      "shape: (5, 3)\n",
      "columns (3): ['Id', 'ranker_id', 'selected']\n",
      "dtypes (first 15):\n",
      "Id            int64\n",
      "ranker_id    object\n",
      "selected      int64\n",
      "dtype: object\n",
      "nulls (top 15):\n",
      "Id           0\n",
      "ranker_id    0\n",
      "selected     0\n",
      "dtype: int64\n",
      "✅ Loaded heads successfully.\n",
      "✅ TRAIN: Suggested key columns present.\n",
      "✅ TEST: Suggested key columns present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Expected submission columns (from sample): ['Id', 'ranker_id', 'selected']\n",
      "⚠️  No submission.csv found yet. After you create it, re-run this cell to validate it.\n",
      "\n",
      "=== Pre-Submission Checklist ===\n",
      "- Data files detected and readable ✔\n",
      "- Heads printed with columns/dtypes ✔\n",
      "- Suggested key columns checked (non-fatal) ✔\n",
      "- sample_submission inspected ✔\n",
      "- submission.csv validated (if present) ✔\n",
      "\n",
      "Tip: Keep a final cell that saves & previews submission:\n",
      "submission_path = OUTPUT_DIR / 'submission.csv'\n",
      "submission.to_csv(submission_path, index=False)\n",
      "print(f'✅ Submission saved to: {submission_path}')\n",
      "display(submission.head())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================= Kaggle Notebook Pre-Submission Validator =======================\n",
    "# What it does:\n",
    "# 1) Detects Kaggle vs Local environment and locates train/test/sample_submission files (csv/parquet).\n",
    "# 2) Loads file heads safely; reports shapes, columns, dtypes, nulls (fast).\n",
    "# 3) Validates your submission.csv against sample_submission.* (column names, dtypes, NaNs, duplicates).\n",
    "# 4) Prints a pass/fail checklist with next-step fixes.\n",
    "\n",
    "import os, sys, gc, json, textwrap, warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------- Config --------------\n",
    "# If running on Kaggle, leave as-is. If local, set these to your data folders.\n",
    "KAGGLE_INPUT_ROOT = Path(\"/kaggle/input\")\n",
    "DEFAULT_INPUT_DIRS = [\n",
    "    KAGGLE_INPUT_ROOT,                      # Kaggle datasets\n",
    "    Path(\"./input\"), Path(\"./data\"), Path(\".\"),  # Local fallbacks\n",
    "]\n",
    "OUTPUT_DIR = Path(\"/kaggle/working\") if Path(\"/kaggle\").exists() else Path(\"./output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Optional: suggest-important columns (won't hard-fail if missing)\n",
    "SUGGESTED_TRAIN_COLS = {\"Id\", \"ranker_id\", \"selected\"}  # adjust if your comp differs\n",
    "SUGGESTED_TEST_COLS  = {\"Id\", \"ranker_id\"}\n",
    "\n",
    "# -------------- Helpers --------------\n",
    "def is_parquet(p: Path) -> bool: return p.suffix.lower() in [\".parquet\", \".pq\"]\n",
    "def is_csv(p: Path) -> bool: return p.suffix.lower() == \".csv\"\n",
    "\n",
    "def find_candidate_files(root_dirs: List[Path]) -> Dict[str, List[Path]]:\n",
    "    hits = {\"train\": [], \"test\": [], \"sample\": [], \"submission\": []}\n",
    "    for root in root_dirs:\n",
    "        if not root.exists(): continue\n",
    "        for p in root.rglob(\"*\"):\n",
    "            if not p.is_file(): continue\n",
    "            name = p.name.lower()\n",
    "            if any(k in name for k in [\"train\"]) and (is_csv(p) or is_parquet(p)):\n",
    "                hits[\"train\"].append(p)\n",
    "            if any(k in name for k in [\"test\"]) and (is_csv(p) or is_parquet(p)):\n",
    "                hits[\"test\"].append(p)\n",
    "            if \"sample_submission\" in name and (is_csv(p) or is_parquet(p)):\n",
    "                hits[\"sample\"].append(p)\n",
    "            if p.name == \"submission.csv\":\n",
    "                hits[\"submission\"].append(p)\n",
    "    return hits\n",
    "\n",
    "def prefer_file(cands: List[Path], prefer_parquet=True) -> Optional[Path]:\n",
    "    if not cands: return None\n",
    "    if prefer_parquet:\n",
    "        for p in cands:\n",
    "            if is_parquet(p): return p\n",
    "    # else first CSV or first file\n",
    "    return cands[0]\n",
    "\n",
    "def load_head(p: Path, n=5) -> pd.DataFrame:\n",
    "    if is_parquet(p):\n",
    "        return pd.read_parquet(p).head(n)\n",
    "    elif is_csv(p):\n",
    "        return pd.read_csv(p, nrows=n)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {p}\")\n",
    "\n",
    "def safe_read(p: Path) -> pd.DataFrame:\n",
    "    if is_parquet(p): return pd.read_parquet(p)\n",
    "    if is_csv(p):     return pd.read_csv(p)\n",
    "    raise ValueError(f\"Unsupported file type: {p}\")\n",
    "\n",
    "def df_info(df: pd.DataFrame, name: str):\n",
    "    print(f\"\\n---- {name} ----\")\n",
    "    print(f\"shape: {df.shape}\")\n",
    "    print(f\"columns ({len(df.columns)}): {list(df.columns)[:20]}{' ...' if len(df.columns)>20 else ''}\")\n",
    "    print(\"dtypes (first 15):\")\n",
    "    print(df.dtypes.head(15))\n",
    "    nulls = df.isnull().sum()\n",
    "    print(\"nulls (top 15):\")\n",
    "    print(nulls.sort_values(ascending=False).head(15))\n",
    "\n",
    "def warn(msg: str): print(f\"⚠️  {msg}\")\n",
    "def ok(msg: str):   print(f\"✅ {msg}\")\n",
    "def fail(msg: str): print(f\"❌ {msg}\")\n",
    "\n",
    "# -------------- Run --------------\n",
    "print(\"=== Environment ===\")\n",
    "on_kaggle = Path(\"/kaggle\").exists()\n",
    "print(f\"Running on Kaggle: {on_kaggle}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "print(\"\\n=== Scanning for files ===\")\n",
    "hits = find_candidate_files(DEFAULT_INPUT_DIRS + [Path(\".\")])\n",
    "train_file = prefer_file(hits[\"train\"], prefer_parquet=True)\n",
    "test_file  = prefer_file(hits[\"test\"], prefer_parquet=True)\n",
    "sample_file= prefer_file(hits[\"sample\"], prefer_parquet=True)\n",
    "submission_file = prefer_file(hits[\"submission\"], prefer_parquet=False)  # your produced submission\n",
    "\n",
    "print(f\"Detected train file: {train_file}\")\n",
    "print(f\"Detected test  file: {test_file}\")\n",
    "print(f\"Detected sample_submission file: {sample_file}\")\n",
    "print(f\"Detected existing submission.csv (optional): {submission_file}\")\n",
    "\n",
    "problems = []\n",
    "\n",
    "if train_file is None:\n",
    "    problems.append(\"Training file not found. Ensure it's named like 'train.*' (csv/parquet) and placed in /kaggle/input/<dataset>/\")\n",
    "if test_file is None:\n",
    "    problems.append(\"Test file not found. Ensure it's named like 'test.*' (csv/parquet).\")\n",
    "if sample_file is None:\n",
    "    problems.append(\"sample_submission file not found. This is needed to validate submission columns & types.\")\n",
    "\n",
    "if problems:\n",
    "    for p in problems: fail(p)\n",
    "    raise SystemExit(\"Fix the file detection issues above and re-run this cell.\")\n",
    "\n",
    "# -------------- Quick peek (heads) --------------\n",
    "try:\n",
    "    train_head = load_head(train_file, n=5)\n",
    "    test_head  = load_head(test_file, n=5)\n",
    "    sample_head= load_head(sample_file, n=5)\n",
    "    df_info(train_head, f\"TRAIN HEAD ({train_file.name})\")\n",
    "    df_info(test_head,  f\"TEST  HEAD ({test_file.name})\")\n",
    "    df_info(sample_head,f\"SAMPLE_SUBMISSION HEAD ({sample_file.name})\")\n",
    "    ok(\"Loaded heads successfully.\")\n",
    "except Exception as e:\n",
    "    fail(f\"Failed to load dataset heads: {e}\")\n",
    "    raise\n",
    "\n",
    "# -------------- Recommended column checks (non-fatal) --------------\n",
    "def check_suggested(df: pd.DataFrame, suggested: set, name: str):\n",
    "    missing = [c for c in suggested if c not in df.columns]\n",
    "    if missing:\n",
    "        warn(f\"{name}: Missing suggested columns {missing}. If your competition schema differs, ignore; otherwise ensure your feature code accounts for these.\")\n",
    "    else:\n",
    "        ok(f\"{name}: Suggested key columns present.\")\n",
    "\n",
    "check_suggested(train_head, SUGGESTED_TRAIN_COLS, \"TRAIN\")\n",
    "check_suggested(test_head,  SUGGESTED_TEST_COLS,  \"TEST\")\n",
    "\n",
    "# -------------- Submission schema validation --------------\n",
    "# Determine expected columns from sample_submission.* (robust to different competitions)\n",
    "try:\n",
    "    sample_full = safe_read(sample_file)\n",
    "    expected_cols = list(sample_full.columns)\n",
    "    if not expected_cols:\n",
    "        fail(\"sample_submission has no columns?\")\n",
    "        raise SystemExit(1)\n",
    "    ok(f\"Expected submission columns (from sample): {expected_cols}\")\n",
    "except Exception as e:\n",
    "    fail(f\"Could not read full sample_submission: {e}\")\n",
    "    raise\n",
    "\n",
    "# If you already have a submission.csv, validate it; else, skip with guidance\n",
    "def validate_submission_csv(path: Path, expected_cols: List[str]) -> bool:\n",
    "    try:\n",
    "        sub = pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        fail(f\"Could not read submission at {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"\\n---- submission.csv ({path.name}) ----\")\n",
    "    print(f\"shape: {sub.shape}\")\n",
    "    print(f\"columns: {list(sub.columns)}\")\n",
    "\n",
    "    ok_count = True\n",
    "\n",
    "    # Column names & order\n",
    "    if list(sub.columns) != expected_cols:\n",
    "        warn(f\"Column names/order mismatch.\\nExpected: {expected_cols}\\nFound:    {list(sub.columns)}\")\n",
    "        ok_count = False\n",
    "    else:\n",
    "        ok(\"Column names & order match sample_submission.\")\n",
    "\n",
    "    # NaNs\n",
    "    na_counts = sub.isna().sum()\n",
    "    if na_counts.any():\n",
    "        warn(f\"Found NaNs in submission:\\n{na_counts[na_counts>0]}\")\n",
    "        ok_count = False\n",
    "    else:\n",
    "        ok(\"No NaNs in submission.\")\n",
    "\n",
    "    # Duplicates on first column (often Id) if it exists\n",
    "    key_col = expected_cols[0]\n",
    "    if key_col in sub.columns:\n",
    "        dups = sub.duplicated(subset=[key_col]).sum()\n",
    "        if dups > 0:\n",
    "            warn(f\"Found {dups} duplicate {key_col} values in submission.\")\n",
    "            ok_count = False\n",
    "        else:\n",
    "            ok(f\"No duplicate {key_col} values.\")\n",
    "\n",
    "    # Size sanity (should usually match sample rows)\n",
    "    try:\n",
    "        if len(sub) != len(sample_full):\n",
    "            warn(f\"Row count differs from sample_submission: expected {len(sample_full)}, found {len(sub)}.\")\n",
    "            ok_count = False\n",
    "        else:\n",
    "            ok(\"Row count matches sample_submission.\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return ok_count\n",
    "\n",
    "if submission_file and submission_file.exists():\n",
    "    sub_ok = validate_submission_csv(submission_file, expected_cols)\n",
    "    if sub_ok:\n",
    "        ok(\"Submission.csv looks VALID ✅\")\n",
    "    else:\n",
    "        warn(\"Submission.csv needs fixes. See messages above.\")\n",
    "else:\n",
    "    warn(\"No submission.csv found yet. After you create it, re-run this cell to validate it.\")\n",
    "\n",
    "print(\"\\n=== Pre-Submission Checklist ===\")\n",
    "print(\"- Data files detected and readable ✔\")\n",
    "print(\"- Heads printed with columns/dtypes ✔\")\n",
    "print(\"- Suggested key columns checked (non-fatal) ✔\")\n",
    "print(\"- sample_submission inspected ✔\")\n",
    "print(\"- submission.csv validated (if present) ✔\")\n",
    "print(\"\\nTip: Keep a final cell that saves & previews submission:\\n\"\n",
    "      \"submission_path = OUTPUT_DIR / 'submission.csv'\\n\"\n",
    "      \"submission.to_csv(submission_path, index=False)\\n\"\n",
    "      \"print(f'✅ Submission saved to: {submission_path}')\\n\"\n",
    "      \"display(submission.head())\")\n",
    "\n",
    "# Free memory\n",
    "del train_head, test_head, sample_head\n",
    "gc.collect()\n",
    "# =================== End Pre-Submission Validator ===================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca642092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:01:25.315427Z",
     "iopub.status.busy": "2025-08-17T05:01:25.315121Z",
     "iopub.status.idle": "2025-08-17T05:01:25.325008Z",
     "shell.execute_reply": "2025-08-17T05:01:25.320406Z"
    },
    "papermill": {
     "duration": 0.027512,
     "end_time": "2025-08-17T05:01:25.327109",
     "exception": false,
     "start_time": "2025-08-17T05:01:25.299597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ./data/\n",
      "Output directory: ./output/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def set_paths():\n",
    "    if 'KAGGLE_WORKING_DIR' in os.environ:\n",
    "        # Kaggle environment\n",
    "        DATA_DIR = '/kaggle/input/'\n",
    "        OUTPUT_DIR = '/kaggle/working/output/'\n",
    "    else:\n",
    "        # Colab or local environment\n",
    "        DATA_DIR = './data/'\n",
    "        OUTPUT_DIR = './output/'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    return DATA_DIR, OUTPUT_DIR\n",
    "\n",
    "DATA_DIR, OUTPUT_DIR = set_paths()\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2142e92e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:01:25.355496Z",
     "iopub.status.busy": "2025-08-17T05:01:25.355292Z",
     "iopub.status.idle": "2025-08-17T05:01:53.902157Z",
     "shell.execute_reply": "2025-08-17T05:01:53.896655Z"
    },
    "papermill": {
     "duration": 28.565445,
     "end_time": "2025-08-17T05:01:53.904940",
     "exception": false,
     "start_time": "2025-08-17T05:01:25.339495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n",
      "Train shape: (18145372, 126)\n",
      "Test shape: (6897776, 125)\n",
      "Sample submission shape: (6897776, 3)\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# %% [code]\n",
    "# Load data from parquet files\n",
    "DATA_DIR = Path(\"/kaggle/input/aeroclub-recsys-2025\")\n",
    "\n",
    "try:\n",
    "    train = pd.read_parquet(DATA_DIR/\"train.parquet\")\n",
    "    test = pd.read_parquet(DATA_DIR/\"test.parquet\")\n",
    "    sample_sub = pd.read_parquet(DATA_DIR/\"sample_submission.parquet\")\n",
    "    \n",
    "    print(\"✅ Data loaded successfully!\")\n",
    "    print(f\"Train shape: {train.shape}\")\n",
    "    print(f\"Test shape: {test.shape}\")\n",
    "    print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(\"❌ Error loading data files. Please check:\")\n",
    "    print(f\"1. The competition dataset is properly added to your Kaggle notebook\")\n",
    "    print(f\"2. The files exist in: {DATA_DIR}\")\n",
    "    print(f\"3. The file names match exactly (case-sensitive)\")\n",
    "    print(\"\\nAvailable files in dataset folder:\")\n",
    "    print(os.listdir(DATA_DIR))\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ca84c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:01:53.934913Z",
     "iopub.status.busy": "2025-08-17T05:01:53.934646Z",
     "iopub.status.idle": "2025-08-17T05:02:28.202591Z",
     "shell.execute_reply": "2025-08-17T05:02:28.198123Z"
    },
    "papermill": {
     "duration": 34.286819,
     "end_time": "2025-08-17T05:02:28.204970",
     "exception": false,
     "start_time": "2025-08-17T05:01:53.918151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files in dataset folder:\n",
      "['jsons_raw.tar.kaggle', 'train.parquet', 'sample_submission.parquet', 'jsons_structure.md', 'test.parquet']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data loaded successfully!\n",
      "Train shape: (18145372, 126)\n",
      "Test shape: (6897776, 125)\n",
      "Sample submission shape: (6897776, 3)\n",
      "\n",
      "Train data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T16:20:00</td>\n",
       "      <td>2024-06-15T15:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>370.0</td>\n",
       "      <td>16884.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>123</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>51125.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>53695.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>123</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>81880.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>86070.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  bySelf  companyID  corporateTariffCode frequentFlyer  nationality  \\\n",
       "0   0    True      57323                 <NA>      S7/SU/UT           36   \n",
       "1   1    True      57323                  123      S7/SU/UT           36   \n",
       "2   2    True      57323                 <NA>      S7/SU/UT           36   \n",
       "3   3    True      57323                  123      S7/SU/UT           36   \n",
       "4   4    True      57323                 <NA>      S7/SU/UT           36   \n",
       "\n",
       "   isAccess3D  isVip      legs0_arrivalAt    legs0_departureAt  ...  \\\n",
       "0       False  False  2024-06-15T16:20:00  2024-06-15T15:40:00  ...   \n",
       "1        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "2       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "3        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "4       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "\n",
       "  pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n",
       "0                    1.0                          1   2087645   \n",
       "1                    1.0                          1   2087645   \n",
       "2                    1.0                          1   2087645   \n",
       "3                    1.0                          1   2087645   \n",
       "4                    1.0                          1   2087645   \n",
       "\n",
       "                          ranker_id         requestDate    searchRoute   sex  \\\n",
       "0  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "1  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "2  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "3  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "4  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "\n",
       "    taxes totalPrice selected  \n",
       "0   370.0    16884.0        1  \n",
       "1  2240.0    51125.0        0  \n",
       "2  2240.0    53695.0        0  \n",
       "3  2240.0    81880.0        0  \n",
       "4  2240.0    86070.0        0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>miniRules1_statusInfos</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18144679</th>\n",
       "      <td>18144679</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>9818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144680</th>\n",
       "      <td>18144680</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>14018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144681</th>\n",
       "      <td>18144681</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>22418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144682</th>\n",
       "      <td>18144682</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T12:45:00</td>\n",
       "      <td>2024-12-19T08:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>12974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144683</th>\n",
       "      <td>18144683</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T12:45:00</td>\n",
       "      <td>2024-12-19T08:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>16974.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  bySelf  companyID  corporateTariffCode frequentFlyer  \\\n",
       "18144679  18144679    True      62840                 <NA>          None   \n",
       "18144680  18144680    True      62840                 <NA>          None   \n",
       "18144681  18144681    True      62840                 <NA>          None   \n",
       "18144682  18144682    True      62840                 <NA>          None   \n",
       "18144683  18144683    True      62840                 <NA>          None   \n",
       "\n",
       "          nationality  isAccess3D  isVip      legs0_arrivalAt  \\\n",
       "18144679           36       False  False  2024-12-19T11:20:00   \n",
       "18144680           36       False  False  2024-12-19T11:20:00   \n",
       "18144681           36       False  False  2024-12-19T11:20:00   \n",
       "18144682           36       False  False  2024-12-19T12:45:00   \n",
       "18144683           36       False  False  2024-12-19T12:45:00   \n",
       "\n",
       "            legs0_departureAt  ... miniRules1_statusInfos  \\\n",
       "18144679  2024-12-19T06:50:00  ...                    0.0   \n",
       "18144680  2024-12-19T06:50:00  ...                    1.0   \n",
       "18144681  2024-12-19T06:50:00  ...                    1.0   \n",
       "18144682  2024-12-19T08:25:00  ...                    0.0   \n",
       "18144683  2024-12-19T08:25:00  ...                    1.0   \n",
       "\n",
       "         pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n",
       "18144679                    1.0                          1   3604015   \n",
       "18144680                    1.0                          1   3604015   \n",
       "18144681                    1.0                          1   3604015   \n",
       "18144682                    1.0                          1   3604015   \n",
       "18144683                    1.0                          1   3604015   \n",
       "\n",
       "                                 ranker_id         requestDate    searchRoute  \\\n",
       "18144679  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144680  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144681  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144682  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144683  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "\n",
       "            sex   taxes totalPrice  \n",
       "18144679  False  1018.0     9818.0  \n",
       "18144680  False  1018.0    14018.0  \n",
       "18144681  False  1018.0    22418.0  \n",
       "18144682  False  3284.0    12974.0  \n",
       "18144683  False  3284.0    16974.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set data directory path\n",
    "DATA_DIR = Path(\"/kaggle/input/aeroclub-recsys-2025\")\n",
    "\n",
    "# List available files to verify\n",
    "print(\"Available files in dataset folder:\")\n",
    "print(os.listdir(DATA_DIR))\n",
    "\n",
    "# Load data from parquet files\n",
    "try:\n",
    "    train = pd.read_parquet(DATA_DIR/\"train.parquet\")\n",
    "    test = pd.read_parquet(DATA_DIR/\"test.parquet\")\n",
    "    sample_sub = pd.read_parquet(DATA_DIR/\"sample_submission.parquet\")\n",
    "    \n",
    "    print(\"\\n✅ Data loaded successfully!\")\n",
    "    print(f\"Train shape: {train.shape}\")\n",
    "    print(f\"Test shape: {test.shape}\")\n",
    "    print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nTrain data preview:\")\n",
    "    display(train.head())\n",
    "    print(\"\\nTest data preview:\")\n",
    "    display(test.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n❌ Error loading data files. Please check:\")\n",
    "    print(\"1. The competition dataset is properly added to your Kaggle notebook\")\n",
    "    print(\"2. The files exist in the specified directory\")\n",
    "    print(\"3. You have permission to access the files\")\n",
    "    print(\"\\nError details:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab85807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:02:28.236490Z",
     "iopub.status.busy": "2025-08-17T05:02:28.236146Z",
     "iopub.status.idle": "2025-08-17T05:02:28.253881Z",
     "shell.execute_reply": "2025-08-17T05:02:28.247465Z"
    },
    "papermill": {
     "duration": 0.037288,
     "end_time": "2025-08-17T05:02:28.256356",
     "exception": false,
     "start_time": "2025-08-17T05:02:28.219068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact file names:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - jsons_raw.tar.kaggle\n",
      " - train.parquet\n",
      " - sample_submission.parquet\n",
      " - jsons_structure.md\n",
      " - test.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact file names:\")\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec871bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:02:28.288313Z",
     "iopub.status.busy": "2025-08-17T05:02:28.288004Z",
     "iopub.status.idle": "2025-08-17T05:04:08.765971Z",
     "shell.execute_reply": "2025-08-17T05:04:08.760233Z"
    },
    "papermill": {
     "duration": 100.504693,
     "end_time": "2025-08-17T05:04:08.775415",
     "exception": false,
     "start_time": "2025-08-17T05:02:28.270722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n",
      "Train shape: (18145372, 126)\n",
      "Test shape: (6897776, 125)\n",
      "Sample submission shape: (6897776, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature engineering completed!\n"
     ]
    }
   ],
   "source": [
    "# First install required packages\n",
    "!pip install lightgbm pyarrow --quiet\n",
    "\n",
    "# Now import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb  # This should now work\n",
    "\n",
    "# Memory cleanup function\n",
    "def clean_memory(vars_to_delete=[]):\n",
    "    for var in vars_to_delete:\n",
    "        if var in globals():\n",
    "            del globals()[var]\n",
    "    gc.collect()\n",
    "\n",
    "# Load data from parquet files\n",
    "DATA_DIR = Path(\"/kaggle/input/aeroclub-recsys-2025\")\n",
    "\n",
    "try:\n",
    "    train = pd.read_parquet(DATA_DIR/\"train.parquet\")\n",
    "    test = pd.read_parquet(DATA_DIR/\"test.parquet\")\n",
    "    sample_sub = pd.read_parquet(DATA_DIR/\"sample_submission.parquet\")\n",
    "    \n",
    "    print(\"✅ Data loaded successfully!\")\n",
    "    print(f\"Train shape: {train.shape}\")\n",
    "    print(f\"Test shape: {test.shape}\")\n",
    "    print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"❌ Error loading data files. Please check:\")\n",
    "    print(f\"1. The competition dataset is properly added to your Kaggle notebook\")\n",
    "    print(f\"2. The files exist in: {DATA_DIR}\")\n",
    "    print(f\"3. The file names match exactly (case-sensitive)\")\n",
    "    print(\"\\nAvailable files in dataset folder:\")\n",
    "    print(os.listdir(DATA_DIR))\n",
    "    raise e\n",
    "\n",
    "# Feature engineering function\n",
    "def create_features(df):\n",
    "    \"\"\"Create features for flight recommendation system\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Time features\n",
    "    df[\"requestDate\"] = pd.to_datetime(df[\"requestDate\"], errors=\"coerce\")\n",
    "    df[\"request_hour\"] = df[\"requestDate\"].dt.hour.fillna(-1).astype(int)\n",
    "    df[\"legs0_departureAt\"] = pd.to_datetime(df[\"legs0_departureAt\"], errors=\"coerce\")\n",
    "    df[\"dep_hour_leg0\"] = df[\"legs0_departureAt\"].dt.hour.fillna(-1).astype(int)\n",
    "    \n",
    "    # Price and duration features\n",
    "    df[\"duration_leg0\"] = pd.to_numeric(df[\"legs0_duration\"], errors=\"coerce\").fillna(-1)\n",
    "    df[\"totalPrice\"] = pd.to_numeric(df[\"totalPrice\"], errors=\"coerce\").fillna(df[\"totalPrice\"].median())\n",
    "    df[\"price_per_hour\"] = df[\"totalPrice\"] / (df[\"duration_leg0\"].replace(0, 1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "print(\"\\nFeature engineering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc2e3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:08.808608Z",
     "iopub.status.busy": "2025-08-17T05:04:08.808162Z",
     "iopub.status.idle": "2025-08-17T05:04:13.199186Z",
     "shell.execute_reply": "2025-08-17T05:04:13.193261Z"
    },
    "papermill": {
     "duration": 4.412243,
     "end_time": "2025-08-17T05:04:13.202419",
     "exception": false,
     "start_time": "2025-08-17T05:04:08.790176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lightgbm\r\n",
      "Version: 4.6.0\r\n",
      "Summary: LightGBM Python-package\r\n",
      "Home-page: https://github.com/microsoft/LightGBM\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: The MIT License (MIT)\r\n",
      "        \r\n",
      "        Copyright (c) Microsoft Corporation\r\n",
      "        \r\n",
      "        Permission is hereby granted, free of charge, to any person obtaining a copy\r\n",
      "        of this software and associated documentation files (the \"Software\"), to deal\r\n",
      "        in the Software without restriction, including without limitation the rights\r\n",
      "        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n",
      "        copies of the Software, and to permit persons to whom the Software is\r\n",
      "        furnished to do so, subject to the following conditions:\r\n",
      "        \r\n",
      "        The above copyright notice and this permission notice shall be included in all\r\n",
      "        copies or substantial portions of the Software.\r\n",
      "        \r\n",
      "        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n",
      "        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n",
      "        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n",
      "        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n",
      "        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n",
      "        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\n",
      "        SOFTWARE.\r\n",
      "Location: /usr/local/lib/python3.10/site-packages\r\n",
      "Requires: numpy, scipy\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a57771",
   "metadata": {
    "id": "0AAljISKv_x5",
    "papermill": {
     "duration": 0.013536,
     "end_time": "2025-08-17T05:04:13.230014",
     "exception": false,
     "start_time": "2025-08-17T05:04:13.216478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " **2. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c64ea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:13.260476Z",
     "iopub.status.busy": "2025-08-17T05:04:13.260176Z",
     "iopub.status.idle": "2025-08-17T05:04:15.334726Z",
     "shell.execute_reply": "2025-08-17T05:04:15.329392Z"
    },
    "id": "h0BcJYuAxtiH",
    "papermill": {
     "duration": 2.094364,
     "end_time": "2025-08-17T05:04:15.337682",
     "exception": false,
     "start_time": "2025-08-17T05:04:13.243318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cece0374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:15.369475Z",
     "iopub.status.busy": "2025-08-17T05:04:15.369076Z",
     "iopub.status.idle": "2025-08-17T05:04:38.901775Z",
     "shell.execute_reply": "2025-08-17T05:04:38.895664Z"
    },
    "papermill": {
     "duration": 23.552197,
     "end_time": "2025-08-17T05:04:38.904079",
     "exception": false,
     "start_time": "2025-08-17T05:04:15.351882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/site-packages (4.6.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading xgboost-3.0.4-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/94.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/94.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/94.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/94.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/94.9 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/94.9 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/94.9 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/94.9 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/94.9 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/94.9 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/94.9 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/94.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/94.9 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.7/94.9 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/94.9 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/94.9 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/94.9 MB\u001b[0m \u001b[31m154.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/94.9 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/94.9 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/94.9 MB\u001b[0m \u001b[31m157.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/94.9 MB\u001b[0m \u001b[31m173.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/94.9 MB\u001b[0m \u001b[31m176.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/94.9 MB\u001b[0m \u001b[31m175.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m70.1/94.9 MB\u001b[0m \u001b[31m175.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m76.1/94.9 MB\u001b[0m \u001b[31m175.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m82.2/94.9 MB\u001b[0m \u001b[31m175.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m88.2/94.9 MB\u001b[0m \u001b[31m175.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.4/94.9 MB\u001b[0m \u001b[31m177.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading catboost-1.2.8-cp310-cp310-manylinux2014_x86_64.whl (99.2 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/99.2 MB\u001b[0m \u001b[31m174.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/99.2 MB\u001b[0m \u001b[31m174.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.8/99.2 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/99.2 MB\u001b[0m \u001b[31m175.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/99.2 MB\u001b[0m \u001b[31m172.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/99.2 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/99.2 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/99.2 MB\u001b[0m \u001b[31m155.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/99.2 MB\u001b[0m \u001b[31m169.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/99.2 MB\u001b[0m \u001b[31m178.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/99.2 MB\u001b[0m \u001b[31m175.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/99.2 MB\u001b[0m \u001b[31m172.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/99.2 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/99.2 MB\u001b[0m \u001b[31m173.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m72.9/99.2 MB\u001b[0m \u001b[31m172.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m78.9/99.2 MB\u001b[0m \u001b[31m172.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m85.0/99.2 MB\u001b[0m \u001b[31m176.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m89.1/99.2 MB\u001b[0m \u001b[31m179.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m91.5/99.2 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m94.7/99.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (2.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\r\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from lightgbm) (1.15.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/site-packages (from xgboost) (2.21.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\r\n",
      "  Downloading plotly-6.3.0-py3-none-any.whl (9.8 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/9.8 MB\u001b[0m \u001b[31m154.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m156.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m156.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\r\n",
      "  Downloading graphviz-0.21-py3-none-any.whl (47 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from catboost) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas) (2025.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from optuna) (4.67.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colorlog\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/site-packages (from optuna) (6.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alembic>=1.5.0\r\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl (247 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy>=1.4.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading sqlalchemy-2.0.43-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m174.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\r\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (2.2.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Mako\r\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting greenlet>=1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/584.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.4/584.4 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting narwhals>=1.15.1\r\n",
      "  Downloading narwhals-2.1.2-py3-none-any.whl (392 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/392.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.1/392.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: narwhals, Mako, greenlet, graphviz, colorlog, xgboost, sqlalchemy, plotly, catboost, alembic, optuna\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed Mako-1.3.10 alembic-1.16.4 catboost-1.2.8 colorlog-6.9.0 graphviz-0.21 greenlet-3.2.4 narwhals-2.1.2 optuna-4.4.0 plotly-6.3.0 sqlalchemy-2.0.43 xgboost-3.0.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install lightgbm xgboost catboost scikit-learn pandas numpy matplotlib optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbccaa57",
   "metadata": {
    "id": "p94lP3GFxtiD",
    "papermill": {
     "duration": 0.020137,
     "end_time": "2025-08-17T05:04:38.945236",
     "exception": false,
     "start_time": "2025-08-17T05:04:38.925099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**📦 3. Environment Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87814f03",
   "metadata": {
    "id": "UumAvxI6xtia",
    "papermill": {
     "duration": 0.01973,
     "end_time": "2025-08-17T05:04:38.985003",
     "exception": false,
     "start_time": "2025-08-17T05:04:38.965273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Overview\n",
    "- `train.parquet` contains user-flight interactions and selection labels.\n",
    "- `test.parquet` is used for prediction.\n",
    "- `jsons_raw` contains additional flight metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7dbdae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:39.028499Z",
     "iopub.status.busy": "2025-08-17T05:04:39.028153Z",
     "iopub.status.idle": "2025-08-17T05:04:39.510856Z",
     "shell.execute_reply": "2025-08-17T05:04:39.506472Z"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1755161519360,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "APL5wZ6BxthW",
    "outputId": "b6b70ee2-b95d-4dd4-a83c-6221dfbf9568",
    "papermill": {
     "duration": 0.508446,
     "end_time": "2025-08-17T05:04:39.513248",
     "exception": false,
     "start_time": "2025-08-17T05:04:39.004802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "ishitabahamnia_flightrank_2025_aeroclub_recsys_cup1_path = kagglehub.notebook_output_download('ishitabahamnia/flightrank-2025-aeroclub-recsys-cup1')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e33ee5",
   "metadata": {
    "id": "1_Op6PQ-xtiL",
    "papermill": {
     "duration": 0.019948,
     "end_time": "2025-08-17T05:04:39.553815",
     "exception": false,
     "start_time": "2025-08-17T05:04:39.533867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**📂 4. Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64fe7eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:39.597015Z",
     "iopub.status.busy": "2025-08-17T05:04:39.596761Z",
     "iopub.status.idle": "2025-08-17T05:04:39.607539Z",
     "shell.execute_reply": "2025-08-17T05:04:39.602999Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755179974154,
     "user": {
      "displayName": "ishita bahamnia",
      "userId": "03625985377702362619"
     },
     "user_tz": -330
    },
    "id": "MAhEg5hkELUw",
    "papermill": {
     "duration": 0.036622,
     "end_time": "2025-08-17T05:04:39.610362",
     "exception": false,
     "start_time": "2025-08-17T05:04:39.573740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set paths - CORRECTED BASE_PATH\n",
    "BASE_PATH = \"/kaggle/input/ishitabahamnia/flightrank-2025-aeroclub-recsys-cup1/\"\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, \"train.parquet\")\n",
    "TEST_PATH = os.path.join(BASE_PATH, \"test.parquet\")\n",
    "JSONS_PATH = os.path.join(BASE_PATH, \"jsons_raw\")\n",
    "SAMPLE_SUB_PATH = os.path.join(BASE_PATH, \"sample_submission.parquet\") # Added sample submission path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd3b2a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:39.653814Z",
     "iopub.status.busy": "2025-08-17T05:04:39.653550Z",
     "iopub.status.idle": "2025-08-17T05:04:44.360003Z",
     "shell.execute_reply": "2025-08-17T05:04:44.354649Z"
    },
    "executionInfo": {
     "elapsed": 3892,
     "status": "ok",
     "timestamp": 1755161678301,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "Gd8FhLQSya98",
    "outputId": "358f8e1e-a822-46e8-8861-49bdba4b2f1f",
    "papermill": {
     "duration": 4.733161,
     "end_time": "2025-08-17T05:04:44.363327",
     "exception": false,
     "start_time": "2025-08-17T05:04:39.630166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/site-packages (20.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d425b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:44.414088Z",
     "iopub.status.busy": "2025-08-17T05:04:44.413770Z",
     "iopub.status.idle": "2025-08-17T05:04:48.999457Z",
     "shell.execute_reply": "2025-08-17T05:04:48.994044Z"
    },
    "executionInfo": {
     "elapsed": 5779,
     "status": "ok",
     "timestamp": 1755161708143,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "AGRXa_EJyhzw",
    "outputId": "a61db601-b099-4d34-bfa1-6a7fd57b3e1c",
    "papermill": {
     "duration": 4.614966,
     "end_time": "2025-08-17T05:04:49.002486",
     "exception": false,
     "start_time": "2025-08-17T05:04:44.387520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /usr/local/lib/python3.10/site-packages (2024.11.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from fastparquet) (25.0)\r\n",
      "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.10/site-packages (from fastparquet) (2.11.0rc3)\r\n",
      "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/site-packages (from fastparquet) (2.3.0)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from fastparquet) (2025.5.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from fastparquet) (2.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd9927",
   "metadata": {
    "id": "xej8eipvxtiV",
    "papermill": {
     "duration": 0.052748,
     "end_time": "2025-08-17T05:04:49.076269",
     "exception": false,
     "start_time": "2025-08-17T05:04:49.023521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**🔍 5. Basic Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd99df94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:49.121320Z",
     "iopub.status.busy": "2025-08-17T05:04:49.120955Z",
     "iopub.status.idle": "2025-08-17T05:04:53.808573Z",
     "shell.execute_reply": "2025-08-17T05:04:53.802448Z"
    },
    "papermill": {
     "duration": 4.714579,
     "end_time": "2025-08-17T05:04:53.811141",
     "exception": false,
     "start_time": "2025-08-17T05:04:49.096562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/site-packages (4.6.0)\r\n",
      "Requirement already satisfied: catboost in /usr/local/lib/python3.10/site-packages (1.2.8)\r\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/site-packages (3.0.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from lightgbm) (1.15.3)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/site-packages (from lightgbm) (2.0.2)\r\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/site-packages (from catboost) (2.3.0)\r\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/site-packages (from catboost) (6.3.0)\r\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/site-packages (from catboost) (0.21)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (from catboost) (3.10.3)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from catboost) (1.17.0)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/site-packages (from xgboost) (2.21.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (3.2.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.8)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (1.3.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (4.58.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (25.0)\r\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.10/site-packages (from plotly->catboost) (2.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm catboost xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f5d0b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:04:53.856864Z",
     "iopub.status.busy": "2025-08-17T05:04:53.856612Z",
     "iopub.status.idle": "2025-08-17T05:06:00.350613Z",
     "shell.execute_reply": "2025-08-17T05:06:00.344494Z"
    },
    "papermill": {
     "duration": 66.534852,
     "end_time": "2025-08-17T05:06:00.367502",
     "exception": false,
     "start_time": "2025-08-17T05:04:53.832650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  legs0_duration\n",
      "0       02:40:00\n",
      "1       07:25:00\n",
      "2       07:25:00\n",
      "3       07:25:00\n",
      "4       07:25:00\n"
     ]
    }
   ],
   "source": [
    "non_numeric = train[\n",
    "    ~train['legs0_duration'].apply(lambda x: isinstance(x, (int, float)))\n",
    "]\n",
    "print(non_numeric[['legs0_duration']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad2261",
   "metadata": {
    "papermill": {
     "duration": 0.020987,
     "end_time": "2025-08-17T05:06:00.410023",
     "exception": false,
     "start_time": "2025-08-17T05:06:00.389036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook contains a **full ML pipeline** for Kaggle competitions:  \n",
    "- Data loading  \n",
    "- EDA + feature engineering  \n",
    "- Model training  \n",
    "- Evaluation (RMSE, plots, feature importances)  \n",
    "- Kaggle submission file generation  \n",
    "- Automated report generation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac35d759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:06:00.455146Z",
     "iopub.status.busy": "2025-08-17T05:06:00.454889Z",
     "iopub.status.idle": "2025-08-17T05:06:05.304263Z",
     "shell.execute_reply": "2025-08-17T05:06:05.299651Z"
    },
    "papermill": {
     "duration": 4.876264,
     "end_time": "2025-08-17T05:06:05.306881",
     "exception": false,
     "start_time": "2025-08-17T05:06:00.430617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/site-packages (3.0.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from xgboost) (1.15.3)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from xgboost) (2.0.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/site-packages (from xgboost) (2.21.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "701bb003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:06:05.353185Z",
     "iopub.status.busy": "2025-08-17T05:06:05.352926Z",
     "iopub.status.idle": "2025-08-17T05:06:17.042708Z",
     "shell.execute_reply": "2025-08-17T05:06:17.036812Z"
    },
    "papermill": {
     "duration": 11.717064,
     "end_time": "2025-08-17T05:06:17.045641",
     "exception": false,
     "start_time": "2025-08-17T05:06:05.328577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading shap-0.48.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (996 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/996.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.4/996.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.4/996.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from shap) (1.15.3)\r\n",
      "Collecting slicer==0.0.8\r\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/site-packages (from shap) (25.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from shap) (4.14.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from shap) (2.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba>=0.54\r\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.8 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/3.8 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from shap) (2.3.0)\r\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/site-packages (from shap) (3.1.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/site-packages (from shap) (4.67.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (from shap) (1.7.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llvmlite<0.45,>=0.44.0dev0\r\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/42.4 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/42.4 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/42.4 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/42.4 MB\u001b[0m \u001b[31m152.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/42.4 MB\u001b[0m \u001b[31m159.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m29.3/42.4 MB\u001b[0m \u001b[31m166.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m34.4/42.4 MB\u001b[0m \u001b[31m157.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m36.7/42.4 MB\u001b[0m \u001b[31m153.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m39.8/42.4 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->shap) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->shap) (2025.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->shap) (2.9.0.post0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->shap) (3.6.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->shap) (1.5.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: slicer, llvmlite, numba, shap\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed llvmlite-0.44.0 numba-0.61.2 shap-0.48.0 slicer-0.0.8\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08212dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:06:17.100057Z",
     "iopub.status.busy": "2025-08-17T05:06:17.099723Z",
     "iopub.status.idle": "2025-08-17T05:06:19.588016Z",
     "shell.execute_reply": "2025-08-17T05:06:19.583576Z"
    },
    "papermill": {
     "duration": 2.519161,
     "end_time": "2025-08-17T05:06:19.590452",
     "exception": false,
     "start_time": "2025-08-17T05:06:17.071291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 📦 1. Setup & Imports\n",
    "# ====================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import ndcg_score\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "# Ensure directories\n",
    "OUTPUT_DIR = \"./output\"\n",
    "FIG_DIR = \"./figures\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "print(\"✅ Setup complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b492d",
   "metadata": {
    "papermill": {
     "duration": 0.022471,
     "end_time": "2025-08-17T05:06:19.636286",
     "exception": false,
     "start_time": "2025-08-17T05:06:19.613815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76292708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:06:19.685617Z",
     "iopub.status.busy": "2025-08-17T05:06:19.685026Z",
     "iopub.status.idle": "2025-08-17T05:10:40.560118Z",
     "shell.execute_reply": "2025-08-17T05:10:40.553805Z"
    },
    "papermill": {
     "duration": 260.90429,
     "end_time": "2025-08-17T05:10:40.563398",
     "exception": false,
     "start_time": "2025-08-17T05:06:19.659108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18145372, 126)\n",
      "Test shape: (6897776, 125)\n",
      "\n",
      "Train Data Overview:\n",
      "========================================\n",
      "1. First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T16:20:00</td>\n",
       "      <td>2024-06-15T15:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>370.0</td>\n",
       "      <td>16884.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>123</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>51125.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>53695.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>123</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>81880.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>86070.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  bySelf  companyID  corporateTariffCode frequentFlyer  nationality  \\\n",
       "0   0    True      57323                 <NA>      S7/SU/UT           36   \n",
       "1   1    True      57323                  123      S7/SU/UT           36   \n",
       "2   2    True      57323                 <NA>      S7/SU/UT           36   \n",
       "3   3    True      57323                  123      S7/SU/UT           36   \n",
       "4   4    True      57323                 <NA>      S7/SU/UT           36   \n",
       "\n",
       "   isAccess3D  isVip      legs0_arrivalAt    legs0_departureAt  ...  \\\n",
       "0       False  False  2024-06-15T16:20:00  2024-06-15T15:40:00  ...   \n",
       "1        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "2       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "3        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "4       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "\n",
       "  pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n",
       "0                    1.0                          1   2087645   \n",
       "1                    1.0                          1   2087645   \n",
       "2                    1.0                          1   2087645   \n",
       "3                    1.0                          1   2087645   \n",
       "4                    1.0                          1   2087645   \n",
       "\n",
       "                          ranker_id         requestDate    searchRoute   sex  \\\n",
       "0  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "1  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "2  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "3  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "4  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "\n",
       "    taxes totalPrice selected  \n",
       "0   370.0    16884.0        1  \n",
       "1  2240.0    51125.0        0  \n",
       "2  2240.0    53695.0        0  \n",
       "3  2240.0    81880.0        0  \n",
       "4  2240.0    86070.0        0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18145372 entries, 0 to 18146431\n",
      "Columns: 126 entries, Id to selected\n",
      "dtypes: Int64(2), bool(4), datetime64[ns](1), float64(41), int64(5), object(73)\n",
      "memory usage: 16.7+ GB\n",
      "None\n",
      "\n",
      "3. Descriptive statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>18145372</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>8911447.0</td>\n",
       "      <td>6132645</td>\n",
       "      <td>18145372.0</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724033e+07</td>\n",
       "      <td>18145372.0</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>1.814537e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>371</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60143</td>\n",
       "      <td>56619</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5769</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SU</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-11-06T17:10:00</td>\n",
       "      <td>2024-11-05T08:05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f9833fe7d58441c8a8feed74fec32a2c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOWLED/LEDMOW</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18145372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3774329</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9233925</td>\n",
       "      <td>17257962</td>\n",
       "      <td>9708</td>\n",
       "      <td>11663</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3250607</td>\n",
       "      <td>10601944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.072686e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.729387e+04</td>\n",
       "      <td>107.084814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.695906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.988453e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.494203e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-19 12:44:59.654136064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.284696e+03</td>\n",
       "      <td>4.631444e+04</td>\n",
       "      <td>5.816304e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.663600e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.130000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.700000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.536343e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.025300e+04</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843022e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-16 08:14:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006000e+03</td>\n",
       "      <td>1.289700e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.072686e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.555500e+04</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.814466e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-27 09:07:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.246000e+03</td>\n",
       "      <td>2.497600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.360903e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.866400e+04</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.301872e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-26 11:49:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.746000e+03</td>\n",
       "      <td>5.510800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.814643e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.348200e+04</td>\n",
       "      <td>181.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.604410e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-29 12:48:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.979210e+05</td>\n",
       "      <td>9.944355e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.238118e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.211986e+04</td>\n",
       "      <td>46.395169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.922091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.999987e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.503914e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.183975e+04</td>\n",
       "      <td>7.506808e+04</td>\n",
       "      <td>7.604259e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id    bySelf     companyID  corporateTariffCode  \\\n",
       "count   1.814537e+07  18145372  1.814537e+07            8911447.0   \n",
       "unique           NaN         1           NaN                 <NA>   \n",
       "top              NaN      True           NaN                 <NA>   \n",
       "freq             NaN  18145372           NaN                 <NA>   \n",
       "mean    9.072686e+06       NaN  4.729387e+04           107.084814   \n",
       "min     0.000000e+00       NaN  1.663600e+04                  0.0   \n",
       "25%     4.536343e+06       NaN  4.025300e+04                 66.0   \n",
       "50%     9.072686e+06       NaN  4.555500e+04                108.0   \n",
       "75%     1.360903e+07       NaN  5.866400e+04                153.0   \n",
       "max     1.814643e+07       NaN  6.348200e+04                181.0   \n",
       "std     5.238118e+06       NaN  1.211986e+04            46.395169   \n",
       "\n",
       "       frequentFlyer  nationality isAccess3D     isVip      legs0_arrivalAt  \\\n",
       "count        6132645   18145372.0   18145372  18145372             18145372   \n",
       "unique           371         <NA>          2         2                60143   \n",
       "top               SU         <NA>      False     False  2024-11-06T17:10:00   \n",
       "freq         3774329         <NA>    9233925  17257962                 9708   \n",
       "mean             NaN    35.695906        NaN       NaN                  NaN   \n",
       "min              NaN          0.0        NaN       NaN                  NaN   \n",
       "25%              NaN         36.0        NaN       NaN                  NaN   \n",
       "50%              NaN         36.0        NaN       NaN                  NaN   \n",
       "75%              NaN         36.0        NaN       NaN                  NaN   \n",
       "max              NaN         48.0        NaN       NaN                  NaN   \n",
       "std              NaN     2.922091        NaN       NaN                  NaN   \n",
       "\n",
       "          legs0_departureAt  ... pricingInfo_isAccessTP  \\\n",
       "count              18145372  ...           1.724033e+07   \n",
       "unique                56619  ...                    NaN   \n",
       "top     2024-11-05T08:05:00  ...                    NaN   \n",
       "freq                  11663  ...                    NaN   \n",
       "mean                    NaN  ...           4.988453e-01   \n",
       "min                     NaN  ...           0.000000e+00   \n",
       "25%                     NaN  ...           0.000000e+00   \n",
       "50%                     NaN  ...           0.000000e+00   \n",
       "75%                     NaN  ...           1.000000e+00   \n",
       "max                     NaN  ...           1.000000e+00   \n",
       "std                     NaN  ...           4.999987e-01   \n",
       "\n",
       "       pricingInfo_passengerCount     profileId  \\\n",
       "count                  18145372.0  1.814537e+07   \n",
       "unique                        NaN           NaN   \n",
       "top                           NaN           NaN   \n",
       "freq                          NaN           NaN   \n",
       "mean                          1.0  2.494203e+06   \n",
       "min                           1.0  8.130000e+02   \n",
       "25%                           1.0  1.843022e+06   \n",
       "50%                           1.0  2.814466e+06   \n",
       "75%                           1.0  3.301872e+06   \n",
       "max                           1.0  3.604410e+06   \n",
       "std                           0.0  9.503914e+05   \n",
       "\n",
       "                               ranker_id                    requestDate  \\\n",
       "count                           18145372                       18145372   \n",
       "unique                            105539                            NaN   \n",
       "top     f9833fe7d58441c8a8feed74fec32a2c                            NaN   \n",
       "freq                                8236                            NaN   \n",
       "mean                                 NaN  2024-08-19 12:44:59.654136064   \n",
       "min                                  NaN            2024-05-17 03:03:08   \n",
       "25%                                  NaN            2024-07-16 08:14:32   \n",
       "50%                                  NaN            2024-08-27 09:07:56   \n",
       "75%                                  NaN            2024-09-26 11:49:57   \n",
       "max                                  NaN            2024-10-29 12:48:50   \n",
       "std                                  NaN                            NaN   \n",
       "\n",
       "          searchRoute       sex         taxes    totalPrice      selected  \n",
       "count        18145372  18145372  1.814537e+07  1.814537e+07  1.814537e+07  \n",
       "unique           5769         2           NaN           NaN           NaN  \n",
       "top     MOWLED/LEDMOW      True           NaN           NaN           NaN  \n",
       "freq          3250607  10601944           NaN           NaN           NaN  \n",
       "mean              NaN       NaN  4.284696e+03  4.631444e+04  5.816304e-03  \n",
       "min               NaN       NaN  0.000000e+00  7.700000e+02  0.000000e+00  \n",
       "25%               NaN       NaN  1.006000e+03  1.289700e+04  0.000000e+00  \n",
       "50%               NaN       NaN  1.246000e+03  2.497600e+04  0.000000e+00  \n",
       "75%               NaN       NaN  1.746000e+03  5.510800e+04  0.000000e+00  \n",
       "max               NaN       NaN  8.979210e+05  9.944355e+06  1.000000e+00  \n",
       "std               NaN       NaN  1.183975e+04  7.506808e+04  7.604259e-02  \n",
       "\n",
       "[11 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corporateTariffCode                             9233925\n",
       "frequentFlyer                                  12012727\n",
       "legs0_segments0_aircraft_code                        14\n",
       "legs0_segments0_arrivalTo_airport_city_iata         113\n",
       "legs0_segments0_arrivalTo_airport_iata                6\n",
       "                                                 ...   \n",
       "miniRules0_statusInfos                          1469953\n",
       "miniRules1_monetaryAmount                       1395743\n",
       "miniRules1_percentage                          17871490\n",
       "miniRules1_statusInfos                          1518169\n",
       "pricingInfo_isAccessTP                           905045\n",
       "Length: 103, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Unique values per column:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bySelf: [ True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isAccess3D: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isVip: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_quantity: [ 1.  0. 20.  2. 25. 23. 30. 40. 35. 50. 10. 60. 15.  3. nan 33. 45. 46.\n",
      " 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_weightMeasurementType: [ 0.  1. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_cabinClass: [1. 2. 4. 3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_seatsAvailable: [ 9.  4.  7.  6.  2.  3.  1.  5.  8. nan 10.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_quantity: [nan  1.  0.  2. 23. 20. 30. 35. 40. 50. 25. 60. 15.  3. 10. 33. 45. 46.\n",
      " 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_seatsAvailable: [nan  4.  1.  9.  8.  3.  2.  5.  6.  7.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_quantity: [nan  1.  2. 40. 25. 30. 35. 50.  0. 20. 23.  3. 15. 45. 33. 60.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_cabinClass: [nan  1.  2.  3.  4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_seatsAvailable: [nan  9.  4.  3.  5.  7.  6.  1.  8.  2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_aircraft_code: [None 'YK4']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_aircraft_code\n",
       "YK4    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_city_iata: [None 'ARH' 'SIA']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_arrivalTo_airport_city_iata\n",
       "SIA    45\n",
       "ARH    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_iata: [None 'ARH' 'XIY']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_arrivalTo_airport_iata\n",
       "XIY    45\n",
       "ARH    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_quantity: [nan  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_weightMeasurementType: [nan  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_cabinClass: [nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_departureFrom_airport_iata: [None 'KSZ' 'KMG' 'PEK' 'NKG' 'SZX']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_departureFrom_airport_iata\n",
       "KMG    38\n",
       "KSZ    13\n",
       "SZX     3\n",
       "PEK     2\n",
       "NKG     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_duration: [None '01:10:00' '02:15:00' '02:20:00' '02:10:00' '03:00:00']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_duration\n",
       "02:10:00    24\n",
       "02:15:00    16\n",
       "01:10:00    13\n",
       "03:00:00     3\n",
       "02:20:00     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_flightNumber: [None '563' '5723' '1289' '2388' '2362' '2263' '3793']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_flightNumber\n",
       "2362    22\n",
       "5723    14\n",
       "563     13\n",
       "3793     3\n",
       "1289     2\n",
       "2388     2\n",
       "2263     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_marketingCarrier_code: [None 'ВГ' 'MU' 'CA' 'CZ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_marketingCarrier_code\n",
       "MU    40\n",
       "ВГ    13\n",
       "CZ     3\n",
       "CA     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_operatingCarrier_code: [None 'ВГ' 'MU' 'CA' 'CZ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_operatingCarrier_code\n",
       "MU    40\n",
       "ВГ    13\n",
       "CZ     3\n",
       "CA     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_seatsAvailable: [nan  9.  2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_quantity: [ 1. nan  2.  0. 10. 23. 30. 20. 40. 35. 50. 25.  3. 60. 15. 45. 33. 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_weightMeasurementType: [ 0. nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_cabinClass: [ 1. nan  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_seatsAvailable: [ 9. nan  6.  1.  2.  4.  5.  8.  3.  7.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_quantity: [nan  1.  2.  0. 23. 20. 30. 35. 40. 50. 25.  3. 60. 10. 15. 45. 33. 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_seatsAvailable: [nan  9.  1.  8.  2.  5.  4.  7.  6.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_quantity: [nan  1. 35. 30.  2. 40. 25.  0. 15. 50. 20. 23. 33.  3. 60.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_seatsAvailable: [nan  9.  2.  5.  1.  4.  8.  7.  3.  6.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_aircraft_code: [None 'YK4']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_aircraft_code\n",
       "YK4    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_city_iata: [None 'ARH']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_arrivalTo_airport_city_iata\n",
       "ARH    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_iata: [None 'ARH']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_arrivalTo_airport_iata\n",
       "ARH    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_quantity: [nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_weightMeasurementType: [nan  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_cabinClass: [nan  1.]\n",
      "\n",
      "legs1_segments3_departureFrom_airport_iata: [None 'KSZ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_departureFrom_airport_iata\n",
       "KSZ    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_duration: [None '01:10:00']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_duration\n",
       "01:10:00    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_flightNumber: [None '563']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_flightNumber\n",
       "563    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_marketingCarrier_code: [None 'ВГ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_marketingCarrier_code\n",
       "ВГ    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_operatingCarrier_code: [None 'ВГ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_operatingCarrier_code\n",
       "ВГ    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_seatsAvailable: [nan  9.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_percentage: [nan  0. 15. 45. 30.  5. 25. 70. 50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_statusInfos: [nan  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_percentage: [nan  0. 25. 65. 10.  5. 70. 15. 30. 40. 35. 50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_statusInfos: [nan  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_isAccessTP: [ 1.  0. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_passengerCount: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sex: [ True False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "selected: [1 0]\n",
      "\n",
      "Test Data Overview:\n",
      "========================================\n",
      "1. First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>miniRules1_statusInfos</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18144679</th>\n",
       "      <td>18144679</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>9818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144680</th>\n",
       "      <td>18144680</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>14018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144681</th>\n",
       "      <td>18144681</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>22418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144682</th>\n",
       "      <td>18144682</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T12:45:00</td>\n",
       "      <td>2024-12-19T08:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>12974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144683</th>\n",
       "      <td>18144683</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T12:45:00</td>\n",
       "      <td>2024-12-19T08:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>16974.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  bySelf  companyID  corporateTariffCode frequentFlyer  \\\n",
       "18144679  18144679    True      62840                 <NA>          None   \n",
       "18144680  18144680    True      62840                 <NA>          None   \n",
       "18144681  18144681    True      62840                 <NA>          None   \n",
       "18144682  18144682    True      62840                 <NA>          None   \n",
       "18144683  18144683    True      62840                 <NA>          None   \n",
       "\n",
       "          nationality  isAccess3D  isVip      legs0_arrivalAt  \\\n",
       "18144679           36       False  False  2024-12-19T11:20:00   \n",
       "18144680           36       False  False  2024-12-19T11:20:00   \n",
       "18144681           36       False  False  2024-12-19T11:20:00   \n",
       "18144682           36       False  False  2024-12-19T12:45:00   \n",
       "18144683           36       False  False  2024-12-19T12:45:00   \n",
       "\n",
       "            legs0_departureAt  ... miniRules1_statusInfos  \\\n",
       "18144679  2024-12-19T06:50:00  ...                    0.0   \n",
       "18144680  2024-12-19T06:50:00  ...                    1.0   \n",
       "18144681  2024-12-19T06:50:00  ...                    1.0   \n",
       "18144682  2024-12-19T08:25:00  ...                    0.0   \n",
       "18144683  2024-12-19T08:25:00  ...                    1.0   \n",
       "\n",
       "         pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n",
       "18144679                    1.0                          1   3604015   \n",
       "18144680                    1.0                          1   3604015   \n",
       "18144681                    1.0                          1   3604015   \n",
       "18144682                    1.0                          1   3604015   \n",
       "18144683                    1.0                          1   3604015   \n",
       "\n",
       "                                 ranker_id         requestDate    searchRoute  \\\n",
       "18144679  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144680  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144681  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144682  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144683  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "\n",
       "            sex   taxes totalPrice  \n",
       "18144679  False  1018.0     9818.0  \n",
       "18144680  False  1018.0    14018.0  \n",
       "18144681  False  1018.0    22418.0  \n",
       "18144682  False  3284.0    12974.0  \n",
       "18144683  False  3284.0    16974.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6897776 entries, 18144679 to 25043147\n",
      "Columns: 125 entries, Id to totalPrice\n",
      "dtypes: Int64(2), bool(4), datetime64[ns](1), float64(41), int64(4), object(73)\n",
      "memory usage: 6.3+ GB\n",
      "None\n",
      "\n",
      "3. Descriptive statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>miniRules1_statusInfos</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>3362441.0</td>\n",
       "      <td>2922856</td>\n",
       "      <td>6897776.0</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>...</td>\n",
       "      <td>6.323344e+06</td>\n",
       "      <td>6.652621e+06</td>\n",
       "      <td>6897776.0</td>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>6.897776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>324</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29117</td>\n",
       "      <td>27294</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3646</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SU</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-03T20:15:00</td>\n",
       "      <td>2025-02-03T16:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccedcdeb3bf646d7abaa9ac6ba1ca9f7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOWLED/LEDMOW</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3702556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1870701</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3535335</td>\n",
       "      <td>6540476</td>\n",
       "      <td>10347</td>\n",
       "      <td>8756</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997387</td>\n",
       "      <td>4123177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.159426e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.450569e+04</td>\n",
       "      <td>96.423325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.771848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.533555e-01</td>\n",
       "      <td>6.215023e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.479011e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-25 13:47:53.790408192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.675951e+03</td>\n",
       "      <td>3.616477e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.814468e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.663600e+04</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.065000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-29 12:49:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.986982e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.694800e+04</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.768469e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-12 14:18:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.560000e+02</td>\n",
       "      <td>1.148800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.159426e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.350900e+04</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.827918e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-25 15:05:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014000e+03</td>\n",
       "      <td>1.856100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.331870e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.691200e+04</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.340421e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-08 05:07:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.479000e+03</td>\n",
       "      <td>3.232300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.504315e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.348200e+04</td>\n",
       "      <td>181.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.667551e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-31 18:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.400970e+05</td>\n",
       "      <td>9.934573e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.991217e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302460e+04</td>\n",
       "      <td>44.523674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.432048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.971451e-01</td>\n",
       "      <td>4.850126e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029326e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.398020e+04</td>\n",
       "      <td>6.719355e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id   bySelf     companyID  corporateTariffCode  \\\n",
       "count   6.897776e+06  6897776  6.897776e+06            3362441.0   \n",
       "unique           NaN        2           NaN                 <NA>   \n",
       "top              NaN    False           NaN                 <NA>   \n",
       "freq             NaN  3702556           NaN                 <NA>   \n",
       "mean    2.159426e+07      NaN  4.450569e+04            96.423325   \n",
       "min     1.814468e+07      NaN  1.663600e+04                 25.0   \n",
       "25%     1.986982e+07      NaN  3.694800e+04                 57.0   \n",
       "50%     2.159426e+07      NaN  4.350900e+04                101.0   \n",
       "75%     2.331870e+07      NaN  5.691200e+04                123.0   \n",
       "max     2.504315e+07      NaN  6.348200e+04                181.0   \n",
       "std     1.991217e+06      NaN  1.302460e+04            44.523674   \n",
       "\n",
       "       frequentFlyer  nationality isAccess3D    isVip      legs0_arrivalAt  \\\n",
       "count        2922856    6897776.0    6897776  6897776              6897776   \n",
       "unique           324         <NA>          2        2                29117   \n",
       "top               SU         <NA>      False    False  2025-02-03T20:15:00   \n",
       "freq         1870701         <NA>    3535335  6540476                10347   \n",
       "mean             NaN    35.771848        NaN      NaN                  NaN   \n",
       "min              NaN          0.0        NaN      NaN                  NaN   \n",
       "25%              NaN         36.0        NaN      NaN                  NaN   \n",
       "50%              NaN         36.0        NaN      NaN                  NaN   \n",
       "75%              NaN         36.0        NaN      NaN                  NaN   \n",
       "max              NaN         47.0        NaN      NaN                  NaN   \n",
       "std              NaN     2.432048        NaN      NaN                  NaN   \n",
       "\n",
       "          legs0_departureAt  ... miniRules1_statusInfos  \\\n",
       "count               6897776  ...           6.323344e+06   \n",
       "unique                27294  ...                    NaN   \n",
       "top     2025-02-03T16:30:00  ...                    NaN   \n",
       "freq                   8756  ...                    NaN   \n",
       "mean                    NaN  ...           5.533555e-01   \n",
       "min                     NaN  ...           0.000000e+00   \n",
       "25%                     NaN  ...           0.000000e+00   \n",
       "50%                     NaN  ...           1.000000e+00   \n",
       "75%                     NaN  ...           1.000000e+00   \n",
       "max                     NaN  ...           1.000000e+00   \n",
       "std                     NaN  ...           4.971451e-01   \n",
       "\n",
       "       pricingInfo_isAccessTP pricingInfo_passengerCount     profileId  \\\n",
       "count            6.652621e+06                  6897776.0  6.897776e+06   \n",
       "unique                    NaN                        NaN           NaN   \n",
       "top                       NaN                        NaN           NaN   \n",
       "freq                      NaN                        NaN           NaN   \n",
       "mean             6.215023e-01                        1.0  2.479011e+06   \n",
       "min              0.000000e+00                        1.0  5.065000e+03   \n",
       "25%              0.000000e+00                        1.0  1.768469e+06   \n",
       "50%              1.000000e+00                        1.0  2.827918e+06   \n",
       "75%              1.000000e+00                        1.0  3.340421e+06   \n",
       "max              1.000000e+00                        1.0  3.667551e+06   \n",
       "std              4.850126e-01                        0.0  1.029326e+06   \n",
       "\n",
       "                               ranker_id                    requestDate  \\\n",
       "count                            6897776                        6897776   \n",
       "unique                             45231                            NaN   \n",
       "top     ccedcdeb3bf646d7abaa9ac6ba1ca9f7                            NaN   \n",
       "freq                                7022                            NaN   \n",
       "mean                                 NaN  2024-11-25 13:47:53.790408192   \n",
       "min                                  NaN            2024-10-29 12:49:43   \n",
       "25%                                  NaN            2024-11-12 14:18:01   \n",
       "50%                                  NaN            2024-11-25 15:05:53   \n",
       "75%                                  NaN            2024-12-08 05:07:10   \n",
       "max                                  NaN            2024-12-31 18:54:00   \n",
       "std                                  NaN                            NaN   \n",
       "\n",
       "          searchRoute      sex         taxes    totalPrice  \n",
       "count         6897776  6897776  6.897776e+06  6.897776e+06  \n",
       "unique           3646        2           NaN           NaN  \n",
       "top     MOWLED/LEDMOW     True           NaN           NaN  \n",
       "freq          1997387  4123177           NaN           NaN  \n",
       "mean              NaN      NaN  4.675951e+03  3.616477e+04  \n",
       "min               NaN      NaN  0.000000e+00  8.000000e+02  \n",
       "25%               NaN      NaN  7.560000e+02  1.148800e+04  \n",
       "50%               NaN      NaN  1.014000e+03  1.856100e+04  \n",
       "75%               NaN      NaN  1.479000e+03  3.232300e+04  \n",
       "max               NaN      NaN  8.400970e+05  9.934573e+06  \n",
       "std               NaN      NaN  1.398020e+04  6.719355e+04  \n",
       "\n",
       "[11 rows x 125 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corporateTariffCode                                       3535335\n",
       "frequentFlyer                                             3974920\n",
       "legs0_segments0_arrivalTo_airport_city_iata                    76\n",
       "legs0_segments0_baggageAllowance_quantity                      20\n",
       "legs0_segments0_baggageAllowance_weightMeasurementType         20\n",
       "                                                           ...   \n",
       "miniRules0_statusInfos                                     550192\n",
       "miniRules1_monetaryAmount                                  504405\n",
       "miniRules1_percentage                                     6756260\n",
       "miniRules1_statusInfos                                     574432\n",
       "pricingInfo_isAccessTP                                     245155\n",
       "Length: 99, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Unique values per column:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bySelf: [ True False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isAccess3D: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isVip: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_quantity: [ 0.  1.  2. 40. 30. 35. 25. 20. 10. 50. 23. 33.  3. 60. 15. 45. 46. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_weightMeasurementType: [ 0.  1. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_cabinClass: [1. 2. 4. 3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_seatsAvailable: [4. 7. 2. 9. 6. 8. 3. 5. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_quantity: [nan  0.  1.  2. 30. 35. 25. 40. 50. 20.  3. 10. 23. 60. 15. 33. 45. 46.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_cabinClass: [nan  1.  2.  3.  4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_seatsAvailable: [nan  9.  4.  3.  5.  8.  2.  1.  7.  6.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_quantity: [nan  1.  2. 25. 30. 35.  0. 40. 50.  3. 20. 45. 23. 15.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_seatsAvailable: [nan  4.  9.  6.  1.  8.  5.  3.  7.  2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_aircraft_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_city_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_quantity: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_weightMeasurementType: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_cabinClass: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_departureFrom_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_duration: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_flightNumber: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_marketingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_operatingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_seatsAvailable: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_quantity: [ 0.  1.  2. nan 30. 35. 25. 10. 20. 23. 50. 40.  3. 33. 60. 15. 45.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_weightMeasurementType: [ 0. nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_cabinClass: [ 1.  2. nan  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_seatsAvailable: [ 4.  3.  2.  7.  9.  6.  8.  1.  5. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_quantity: [nan  0.  1.  2. 30. 35. 25. 20. 50. 40.  3. 60. 23. 10. 33. 45.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_seatsAvailable: [nan  9.  3.  6.  2.  4.  8.  1.  7.  5.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_quantity: [nan  1.  0. 30. 35.  2. 40. 25. 20. 50. 45.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_seatsAvailable: [nan  9.  8.  2.  6.  4.  7.  3.  1.  5.]\n",
      "\n",
      "legs1_segments3_aircraft_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_city_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_quantity: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_weightMeasurementType: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_cabinClass: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_departureFrom_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_duration: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_flightNumber: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_marketingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_operatingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_seatsAvailable: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_percentage: [nan  0. 45.  5. 15. 50. 25.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_statusInfos: [ 1.  0. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_percentage: [nan  0. 65. 10. 25. 70. 35.  5. 15. 50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_statusInfos: [ 0.  1. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_isAccessTP: [ 1.  0. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_passengerCount: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sex: [False  True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path configuration - works for both Kaggle and local\n",
    "DATA_DIR = \"./data\" if os.path.exists(\"./data\") else \"/kaggle/input/aeroclub-recsys-2025\"\n",
    "\n",
    "def load_data(data_dir=DATA_DIR):\n",
    "    \"\"\"Load dataset with automatic path detection\"\"\"\n",
    "    try:\n",
    "        # Try parquet first (more efficient)\n",
    "        try:\n",
    "            train_df = pd.read_parquet(f'{data_dir}/train.parquet')\n",
    "            test_df = pd.read_parquet(f'{data_dir}/test.parquet')\n",
    "        except:\n",
    "            # Fall back to CSV if parquet not available\n",
    "            train_df = pd.read_csv(f'{data_dir}/train.csv')\n",
    "            test_df = pd.read_csv(f'{data_dir}/test.csv')\n",
    "        \n",
    "        print(\"Train shape:\", train_df.shape)\n",
    "        print(\"Test shape:\", test_df.shape)\n",
    "        \n",
    "        # Basic validation\n",
    "        assert not train_df.empty, \"Train data is empty!\"\n",
    "        assert not test_df.empty, \"Test data is empty!\"\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load data\n",
    "train_df, test_df = load_data()\n",
    "\n",
    "# Initial exploration\n",
    "def explore_data(df, name=\"Train\"):\n",
    "    print(f\"\\n{name} Data Overview:\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"1. First 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\n2. Basic info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n3. Descriptive statistics:\")\n",
    "    display(df.describe(include='all'))\n",
    "    \n",
    "    print(\"\\n4. Missing values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    display(missing[missing > 0])\n",
    "    \n",
    "    print(\"\\n5. Unique values per column:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() < 20:\n",
    "            print(f\"\\n{col}: {df[col].unique()}\")\n",
    "            if df[col].dtype == 'object':\n",
    "                print(\"Value counts:\")\n",
    "                display(df[col].value_counts())\n",
    "\n",
    "# Explore train data\n",
    "explore_data(train_df, \"Train\")\n",
    "\n",
    "# Explore test data (without target if exists)\n",
    "explore_data(test_df, \"Test\")\n",
    "\n",
    "# Key columns check\n",
    "required_cols = ['ranker_id', 'totalPrice', 'legs0_duration']\n",
    "for col in required_cols:\n",
    "    assert col in train_df.columns, f\"Missing required column in train: {col}\"\n",
    "    assert col in test_df.columns, f\"Missing required column in test: {col}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00494c9",
   "metadata": {
    "papermill": {
     "duration": 0.033233,
     "end_time": "2025-08-17T05:10:40.630732",
     "exception": false,
     "start_time": "2025-08-17T05:10:40.597499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Feature Engineering\n",
    "- Encode categoricals\n",
    "- Scale numerical features\n",
    "- Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b86a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:10:40.701773Z",
     "iopub.status.busy": "2025-08-17T05:10:40.701421Z",
     "iopub.status.idle": "2025-08-17T05:15:04.969546Z",
     "shell.execute_reply": "2025-08-17T05:15:04.963178Z"
    },
    "papermill": {
     "duration": 264.308563,
     "end_time": "2025-08-17T05:15:04.972152",
     "exception": false,
     "start_time": "2025-08-17T05:10:40.663589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18145372, 126)\n",
      "Test shape: (6897776, 125)\n",
      "\n",
      "Train Data Overview:\n",
      "========================================\n",
      "1. First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T16:20:00</td>\n",
       "      <td>2024-06-15T15:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>370.0</td>\n",
       "      <td>16884.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>123</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>51125.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>53695.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>123</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>81880.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>57323</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>S7/SU/UT</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-06-15T14:50:00</td>\n",
       "      <td>2024-06-15T09:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2087645</td>\n",
       "      <td>98ce0dabf6964640b63079fbafd42cbe</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>TLKKJA/KJATLK</td>\n",
       "      <td>True</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>86070.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  bySelf  companyID  corporateTariffCode frequentFlyer  nationality  \\\n",
       "0   0    True      57323                 <NA>      S7/SU/UT           36   \n",
       "1   1    True      57323                  123      S7/SU/UT           36   \n",
       "2   2    True      57323                 <NA>      S7/SU/UT           36   \n",
       "3   3    True      57323                  123      S7/SU/UT           36   \n",
       "4   4    True      57323                 <NA>      S7/SU/UT           36   \n",
       "\n",
       "   isAccess3D  isVip      legs0_arrivalAt    legs0_departureAt  ...  \\\n",
       "0       False  False  2024-06-15T16:20:00  2024-06-15T15:40:00  ...   \n",
       "1        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "2       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "3        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "4       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n",
       "\n",
       "  pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n",
       "0                    1.0                          1   2087645   \n",
       "1                    1.0                          1   2087645   \n",
       "2                    1.0                          1   2087645   \n",
       "3                    1.0                          1   2087645   \n",
       "4                    1.0                          1   2087645   \n",
       "\n",
       "                          ranker_id         requestDate    searchRoute   sex  \\\n",
       "0  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "1  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "2  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "3  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "4  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n",
       "\n",
       "    taxes totalPrice selected  \n",
       "0   370.0    16884.0        1  \n",
       "1  2240.0    51125.0        0  \n",
       "2  2240.0    53695.0        0  \n",
       "3  2240.0    81880.0        0  \n",
       "4  2240.0    86070.0        0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18145372 entries, 0 to 18146431\n",
      "Columns: 126 entries, Id to selected\n",
      "dtypes: Int64(2), bool(4), datetime64[ns](1), float64(41), int64(5), object(73)\n",
      "memory usage: 16.7+ GB\n",
      "None\n",
      "\n",
      "3. Descriptive statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>18145372</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>8911447.0</td>\n",
       "      <td>6132645</td>\n",
       "      <td>18145372.0</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724033e+07</td>\n",
       "      <td>18145372.0</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>18145372</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>1.814537e+07</td>\n",
       "      <td>1.814537e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>371</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60143</td>\n",
       "      <td>56619</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5769</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SU</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-11-06T17:10:00</td>\n",
       "      <td>2024-11-05T08:05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f9833fe7d58441c8a8feed74fec32a2c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOWLED/LEDMOW</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18145372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3774329</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9233925</td>\n",
       "      <td>17257962</td>\n",
       "      <td>9708</td>\n",
       "      <td>11663</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3250607</td>\n",
       "      <td>10601944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.072686e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.729387e+04</td>\n",
       "      <td>107.084814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.695906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.988453e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.494203e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-19 12:44:59.654136064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.284696e+03</td>\n",
       "      <td>4.631444e+04</td>\n",
       "      <td>5.816304e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.663600e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.130000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-17 03:03:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.700000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.536343e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.025300e+04</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843022e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-16 08:14:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006000e+03</td>\n",
       "      <td>1.289700e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.072686e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.555500e+04</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.814466e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-27 09:07:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.246000e+03</td>\n",
       "      <td>2.497600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.360903e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.866400e+04</td>\n",
       "      <td>153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.301872e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-26 11:49:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.746000e+03</td>\n",
       "      <td>5.510800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.814643e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.348200e+04</td>\n",
       "      <td>181.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.604410e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-29 12:48:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.979210e+05</td>\n",
       "      <td>9.944355e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.238118e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.211986e+04</td>\n",
       "      <td>46.395169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.922091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.999987e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.503914e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.183975e+04</td>\n",
       "      <td>7.506808e+04</td>\n",
       "      <td>7.604259e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id    bySelf     companyID  corporateTariffCode  \\\n",
       "count   1.814537e+07  18145372  1.814537e+07            8911447.0   \n",
       "unique           NaN         1           NaN                 <NA>   \n",
       "top              NaN      True           NaN                 <NA>   \n",
       "freq             NaN  18145372           NaN                 <NA>   \n",
       "mean    9.072686e+06       NaN  4.729387e+04           107.084814   \n",
       "min     0.000000e+00       NaN  1.663600e+04                  0.0   \n",
       "25%     4.536343e+06       NaN  4.025300e+04                 66.0   \n",
       "50%     9.072686e+06       NaN  4.555500e+04                108.0   \n",
       "75%     1.360903e+07       NaN  5.866400e+04                153.0   \n",
       "max     1.814643e+07       NaN  6.348200e+04                181.0   \n",
       "std     5.238118e+06       NaN  1.211986e+04            46.395169   \n",
       "\n",
       "       frequentFlyer  nationality isAccess3D     isVip      legs0_arrivalAt  \\\n",
       "count        6132645   18145372.0   18145372  18145372             18145372   \n",
       "unique           371         <NA>          2         2                60143   \n",
       "top               SU         <NA>      False     False  2024-11-06T17:10:00   \n",
       "freq         3774329         <NA>    9233925  17257962                 9708   \n",
       "mean             NaN    35.695906        NaN       NaN                  NaN   \n",
       "min              NaN          0.0        NaN       NaN                  NaN   \n",
       "25%              NaN         36.0        NaN       NaN                  NaN   \n",
       "50%              NaN         36.0        NaN       NaN                  NaN   \n",
       "75%              NaN         36.0        NaN       NaN                  NaN   \n",
       "max              NaN         48.0        NaN       NaN                  NaN   \n",
       "std              NaN     2.922091        NaN       NaN                  NaN   \n",
       "\n",
       "          legs0_departureAt  ... pricingInfo_isAccessTP  \\\n",
       "count              18145372  ...           1.724033e+07   \n",
       "unique                56619  ...                    NaN   \n",
       "top     2024-11-05T08:05:00  ...                    NaN   \n",
       "freq                  11663  ...                    NaN   \n",
       "mean                    NaN  ...           4.988453e-01   \n",
       "min                     NaN  ...           0.000000e+00   \n",
       "25%                     NaN  ...           0.000000e+00   \n",
       "50%                     NaN  ...           0.000000e+00   \n",
       "75%                     NaN  ...           1.000000e+00   \n",
       "max                     NaN  ...           1.000000e+00   \n",
       "std                     NaN  ...           4.999987e-01   \n",
       "\n",
       "       pricingInfo_passengerCount     profileId  \\\n",
       "count                  18145372.0  1.814537e+07   \n",
       "unique                        NaN           NaN   \n",
       "top                           NaN           NaN   \n",
       "freq                          NaN           NaN   \n",
       "mean                          1.0  2.494203e+06   \n",
       "min                           1.0  8.130000e+02   \n",
       "25%                           1.0  1.843022e+06   \n",
       "50%                           1.0  2.814466e+06   \n",
       "75%                           1.0  3.301872e+06   \n",
       "max                           1.0  3.604410e+06   \n",
       "std                           0.0  9.503914e+05   \n",
       "\n",
       "                               ranker_id                    requestDate  \\\n",
       "count                           18145372                       18145372   \n",
       "unique                            105539                            NaN   \n",
       "top     f9833fe7d58441c8a8feed74fec32a2c                            NaN   \n",
       "freq                                8236                            NaN   \n",
       "mean                                 NaN  2024-08-19 12:44:59.654136064   \n",
       "min                                  NaN            2024-05-17 03:03:08   \n",
       "25%                                  NaN            2024-07-16 08:14:32   \n",
       "50%                                  NaN            2024-08-27 09:07:56   \n",
       "75%                                  NaN            2024-09-26 11:49:57   \n",
       "max                                  NaN            2024-10-29 12:48:50   \n",
       "std                                  NaN                            NaN   \n",
       "\n",
       "          searchRoute       sex         taxes    totalPrice      selected  \n",
       "count        18145372  18145372  1.814537e+07  1.814537e+07  1.814537e+07  \n",
       "unique           5769         2           NaN           NaN           NaN  \n",
       "top     MOWLED/LEDMOW      True           NaN           NaN           NaN  \n",
       "freq          3250607  10601944           NaN           NaN           NaN  \n",
       "mean              NaN       NaN  4.284696e+03  4.631444e+04  5.816304e-03  \n",
       "min               NaN       NaN  0.000000e+00  7.700000e+02  0.000000e+00  \n",
       "25%               NaN       NaN  1.006000e+03  1.289700e+04  0.000000e+00  \n",
       "50%               NaN       NaN  1.246000e+03  2.497600e+04  0.000000e+00  \n",
       "75%               NaN       NaN  1.746000e+03  5.510800e+04  0.000000e+00  \n",
       "max               NaN       NaN  8.979210e+05  9.944355e+06  1.000000e+00  \n",
       "std               NaN       NaN  1.183975e+04  7.506808e+04  7.604259e-02  \n",
       "\n",
       "[11 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corporateTariffCode                             9233925\n",
       "frequentFlyer                                  12012727\n",
       "legs0_segments0_aircraft_code                        14\n",
       "legs0_segments0_arrivalTo_airport_city_iata         113\n",
       "legs0_segments0_arrivalTo_airport_iata                6\n",
       "                                                 ...   \n",
       "miniRules0_statusInfos                          1469953\n",
       "miniRules1_monetaryAmount                       1395743\n",
       "miniRules1_percentage                          17871490\n",
       "miniRules1_statusInfos                          1518169\n",
       "pricingInfo_isAccessTP                           905045\n",
       "Length: 103, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Unique values per column:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bySelf: [ True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isAccess3D: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isVip: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_quantity: [ 1.  0. 20.  2. 25. 23. 30. 40. 35. 50. 10. 60. 15.  3. nan 33. 45. 46.\n",
      " 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_weightMeasurementType: [ 0.  1. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_cabinClass: [1. 2. 4. 3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_seatsAvailable: [ 9.  4.  7.  6.  2.  3.  1.  5.  8. nan 10.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_quantity: [nan  1.  0.  2. 23. 20. 30. 35. 40. 50. 25. 60. 15.  3. 10. 33. 45. 46.\n",
      " 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_seatsAvailable: [nan  4.  1.  9.  8.  3.  2.  5.  6.  7.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_quantity: [nan  1.  2. 40. 25. 30. 35. 50.  0. 20. 23.  3. 15. 45. 33. 60.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_cabinClass: [nan  1.  2.  3.  4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_seatsAvailable: [nan  9.  4.  3.  5.  7.  6.  1.  8.  2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_aircraft_code: [None 'YK4']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_aircraft_code\n",
       "YK4    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_city_iata: [None 'ARH' 'SIA']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_arrivalTo_airport_city_iata\n",
       "SIA    45\n",
       "ARH    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_iata: [None 'ARH' 'XIY']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_arrivalTo_airport_iata\n",
       "XIY    45\n",
       "ARH    13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_quantity: [nan  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_weightMeasurementType: [nan  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_cabinClass: [nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_departureFrom_airport_iata: [None 'KSZ' 'KMG' 'PEK' 'NKG' 'SZX']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_departureFrom_airport_iata\n",
       "KMG    38\n",
       "KSZ    13\n",
       "SZX     3\n",
       "PEK     2\n",
       "NKG     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_duration: [None '01:10:00' '02:15:00' '02:20:00' '02:10:00' '03:00:00']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_duration\n",
       "02:10:00    24\n",
       "02:15:00    16\n",
       "01:10:00    13\n",
       "03:00:00     3\n",
       "02:20:00     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_flightNumber: [None '563' '5723' '1289' '2388' '2362' '2263' '3793']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_flightNumber\n",
       "2362    22\n",
       "5723    14\n",
       "563     13\n",
       "3793     3\n",
       "1289     2\n",
       "2388     2\n",
       "2263     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_marketingCarrier_code: [None 'ВГ' 'MU' 'CA' 'CZ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_marketingCarrier_code\n",
       "MU    40\n",
       "ВГ    13\n",
       "CZ     3\n",
       "CA     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_operatingCarrier_code: [None 'ВГ' 'MU' 'CA' 'CZ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs0_segments3_operatingCarrier_code\n",
       "MU    40\n",
       "ВГ    13\n",
       "CZ     3\n",
       "CA     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_seatsAvailable: [nan  9.  2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_quantity: [ 1. nan  2.  0. 10. 23. 30. 20. 40. 35. 50. 25.  3. 60. 15. 45. 33. 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_weightMeasurementType: [ 0. nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_cabinClass: [ 1. nan  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_seatsAvailable: [ 9. nan  6.  1.  2.  4.  5.  8.  3.  7.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_quantity: [nan  1.  2.  0. 23. 20. 30. 35. 40. 50. 25.  3. 60. 10. 15. 45. 33. 32.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_seatsAvailable: [nan  9.  1.  8.  2.  5.  4.  7.  6.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_quantity: [nan  1. 35. 30.  2. 40. 25.  0. 15. 50. 20. 23. 33.  3. 60.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_seatsAvailable: [nan  9.  2.  5.  1.  4.  8.  7.  3.  6.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_aircraft_code: [None 'YK4']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_aircraft_code\n",
       "YK4    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_city_iata: [None 'ARH']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_arrivalTo_airport_city_iata\n",
       "ARH    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_iata: [None 'ARH']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_arrivalTo_airport_iata\n",
       "ARH    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_quantity: [nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_weightMeasurementType: [nan  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_cabinClass: [nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_departureFrom_airport_iata: [None 'KSZ']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_departureFrom_airport_iata\n",
       "KSZ    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_duration: [None '01:10:00']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_duration\n",
       "01:10:00    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_flightNumber: [None '563']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_flightNumber\n",
       "563    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_marketingCarrier_code: [None 'ВГ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_marketingCarrier_code\n",
       "ВГ    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_operatingCarrier_code: [None 'ВГ']\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "legs1_segments3_operatingCarrier_code\n",
       "ВГ    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_seatsAvailable: [nan  9.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_percentage: [nan  0. 15. 45. 30.  5. 25. 70. 50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_statusInfos: [nan  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_percentage: [nan  0. 25. 65. 10.  5. 70. 15. 30. 40. 35. 50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_statusInfos: [nan  1.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_isAccessTP: [ 1.  0. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_passengerCount: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sex: [ True False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "selected: [1 0]\n",
      "\n",
      "Test Data Overview:\n",
      "========================================\n",
      "1. First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>miniRules1_statusInfos</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18144679</th>\n",
       "      <td>18144679</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>9818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144680</th>\n",
       "      <td>18144680</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>14018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144681</th>\n",
       "      <td>18144681</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T11:20:00</td>\n",
       "      <td>2024-12-19T06:50:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>22418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144682</th>\n",
       "      <td>18144682</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T12:45:00</td>\n",
       "      <td>2024-12-19T08:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>12974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144683</th>\n",
       "      <td>18144683</td>\n",
       "      <td>True</td>\n",
       "      <td>62840</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-12-19T12:45:00</td>\n",
       "      <td>2024-12-19T08:25:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3604015</td>\n",
       "      <td>c9373e5f772e43d593dd6ad2fa90f67a</td>\n",
       "      <td>2024-10-29 12:50:42</td>\n",
       "      <td>MOWSVX/SVXMOW</td>\n",
       "      <td>False</td>\n",
       "      <td>3284.0</td>\n",
       "      <td>16974.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  bySelf  companyID  corporateTariffCode frequentFlyer  \\\n",
       "18144679  18144679    True      62840                 <NA>          None   \n",
       "18144680  18144680    True      62840                 <NA>          None   \n",
       "18144681  18144681    True      62840                 <NA>          None   \n",
       "18144682  18144682    True      62840                 <NA>          None   \n",
       "18144683  18144683    True      62840                 <NA>          None   \n",
       "\n",
       "          nationality  isAccess3D  isVip      legs0_arrivalAt  \\\n",
       "18144679           36       False  False  2024-12-19T11:20:00   \n",
       "18144680           36       False  False  2024-12-19T11:20:00   \n",
       "18144681           36       False  False  2024-12-19T11:20:00   \n",
       "18144682           36       False  False  2024-12-19T12:45:00   \n",
       "18144683           36       False  False  2024-12-19T12:45:00   \n",
       "\n",
       "            legs0_departureAt  ... miniRules1_statusInfos  \\\n",
       "18144679  2024-12-19T06:50:00  ...                    0.0   \n",
       "18144680  2024-12-19T06:50:00  ...                    1.0   \n",
       "18144681  2024-12-19T06:50:00  ...                    1.0   \n",
       "18144682  2024-12-19T08:25:00  ...                    0.0   \n",
       "18144683  2024-12-19T08:25:00  ...                    1.0   \n",
       "\n",
       "         pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n",
       "18144679                    1.0                          1   3604015   \n",
       "18144680                    1.0                          1   3604015   \n",
       "18144681                    1.0                          1   3604015   \n",
       "18144682                    1.0                          1   3604015   \n",
       "18144683                    1.0                          1   3604015   \n",
       "\n",
       "                                 ranker_id         requestDate    searchRoute  \\\n",
       "18144679  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144680  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144681  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144682  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "18144683  c9373e5f772e43d593dd6ad2fa90f67a 2024-10-29 12:50:42  MOWSVX/SVXMOW   \n",
       "\n",
       "            sex   taxes totalPrice  \n",
       "18144679  False  1018.0     9818.0  \n",
       "18144680  False  1018.0    14018.0  \n",
       "18144681  False  1018.0    22418.0  \n",
       "18144682  False  3284.0    12974.0  \n",
       "18144683  False  3284.0    16974.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6897776 entries, 18144679 to 25043147\n",
      "Columns: 125 entries, Id to totalPrice\n",
      "dtypes: Int64(2), bool(4), datetime64[ns](1), float64(41), int64(4), object(73)\n",
      "memory usage: 6.3+ GB\n",
      "None\n",
      "\n",
      "3. Descriptive statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>bySelf</th>\n",
       "      <th>companyID</th>\n",
       "      <th>corporateTariffCode</th>\n",
       "      <th>frequentFlyer</th>\n",
       "      <th>nationality</th>\n",
       "      <th>isAccess3D</th>\n",
       "      <th>isVip</th>\n",
       "      <th>legs0_arrivalAt</th>\n",
       "      <th>legs0_departureAt</th>\n",
       "      <th>...</th>\n",
       "      <th>miniRules1_statusInfos</th>\n",
       "      <th>pricingInfo_isAccessTP</th>\n",
       "      <th>pricingInfo_passengerCount</th>\n",
       "      <th>profileId</th>\n",
       "      <th>ranker_id</th>\n",
       "      <th>requestDate</th>\n",
       "      <th>searchRoute</th>\n",
       "      <th>sex</th>\n",
       "      <th>taxes</th>\n",
       "      <th>totalPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>3362441.0</td>\n",
       "      <td>2922856</td>\n",
       "      <td>6897776.0</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>...</td>\n",
       "      <td>6.323344e+06</td>\n",
       "      <td>6.652621e+06</td>\n",
       "      <td>6897776.0</td>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6897776</td>\n",
       "      <td>6.897776e+06</td>\n",
       "      <td>6.897776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>324</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29117</td>\n",
       "      <td>27294</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3646</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SU</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-02-03T20:15:00</td>\n",
       "      <td>2025-02-03T16:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccedcdeb3bf646d7abaa9ac6ba1ca9f7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOWLED/LEDMOW</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3702556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1870701</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3535335</td>\n",
       "      <td>6540476</td>\n",
       "      <td>10347</td>\n",
       "      <td>8756</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997387</td>\n",
       "      <td>4123177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.159426e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.450569e+04</td>\n",
       "      <td>96.423325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.771848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.533555e-01</td>\n",
       "      <td>6.215023e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.479011e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-25 13:47:53.790408192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.675951e+03</td>\n",
       "      <td>3.616477e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.814468e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.663600e+04</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.065000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-29 12:49:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.986982e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.694800e+04</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.768469e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-12 14:18:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.560000e+02</td>\n",
       "      <td>1.148800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.159426e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.350900e+04</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.827918e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-25 15:05:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014000e+03</td>\n",
       "      <td>1.856100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.331870e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.691200e+04</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.340421e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-08 05:07:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.479000e+03</td>\n",
       "      <td>3.232300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.504315e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.348200e+04</td>\n",
       "      <td>181.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.667551e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-31 18:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.400970e+05</td>\n",
       "      <td>9.934573e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.991217e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302460e+04</td>\n",
       "      <td>44.523674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.432048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.971451e-01</td>\n",
       "      <td>4.850126e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029326e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.398020e+04</td>\n",
       "      <td>6.719355e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id   bySelf     companyID  corporateTariffCode  \\\n",
       "count   6.897776e+06  6897776  6.897776e+06            3362441.0   \n",
       "unique           NaN        2           NaN                 <NA>   \n",
       "top              NaN    False           NaN                 <NA>   \n",
       "freq             NaN  3702556           NaN                 <NA>   \n",
       "mean    2.159426e+07      NaN  4.450569e+04            96.423325   \n",
       "min     1.814468e+07      NaN  1.663600e+04                 25.0   \n",
       "25%     1.986982e+07      NaN  3.694800e+04                 57.0   \n",
       "50%     2.159426e+07      NaN  4.350900e+04                101.0   \n",
       "75%     2.331870e+07      NaN  5.691200e+04                123.0   \n",
       "max     2.504315e+07      NaN  6.348200e+04                181.0   \n",
       "std     1.991217e+06      NaN  1.302460e+04            44.523674   \n",
       "\n",
       "       frequentFlyer  nationality isAccess3D    isVip      legs0_arrivalAt  \\\n",
       "count        2922856    6897776.0    6897776  6897776              6897776   \n",
       "unique           324         <NA>          2        2                29117   \n",
       "top               SU         <NA>      False    False  2025-02-03T20:15:00   \n",
       "freq         1870701         <NA>    3535335  6540476                10347   \n",
       "mean             NaN    35.771848        NaN      NaN                  NaN   \n",
       "min              NaN          0.0        NaN      NaN                  NaN   \n",
       "25%              NaN         36.0        NaN      NaN                  NaN   \n",
       "50%              NaN         36.0        NaN      NaN                  NaN   \n",
       "75%              NaN         36.0        NaN      NaN                  NaN   \n",
       "max              NaN         47.0        NaN      NaN                  NaN   \n",
       "std              NaN     2.432048        NaN      NaN                  NaN   \n",
       "\n",
       "          legs0_departureAt  ... miniRules1_statusInfos  \\\n",
       "count               6897776  ...           6.323344e+06   \n",
       "unique                27294  ...                    NaN   \n",
       "top     2025-02-03T16:30:00  ...                    NaN   \n",
       "freq                   8756  ...                    NaN   \n",
       "mean                    NaN  ...           5.533555e-01   \n",
       "min                     NaN  ...           0.000000e+00   \n",
       "25%                     NaN  ...           0.000000e+00   \n",
       "50%                     NaN  ...           1.000000e+00   \n",
       "75%                     NaN  ...           1.000000e+00   \n",
       "max                     NaN  ...           1.000000e+00   \n",
       "std                     NaN  ...           4.971451e-01   \n",
       "\n",
       "       pricingInfo_isAccessTP pricingInfo_passengerCount     profileId  \\\n",
       "count            6.652621e+06                  6897776.0  6.897776e+06   \n",
       "unique                    NaN                        NaN           NaN   \n",
       "top                       NaN                        NaN           NaN   \n",
       "freq                      NaN                        NaN           NaN   \n",
       "mean             6.215023e-01                        1.0  2.479011e+06   \n",
       "min              0.000000e+00                        1.0  5.065000e+03   \n",
       "25%              0.000000e+00                        1.0  1.768469e+06   \n",
       "50%              1.000000e+00                        1.0  2.827918e+06   \n",
       "75%              1.000000e+00                        1.0  3.340421e+06   \n",
       "max              1.000000e+00                        1.0  3.667551e+06   \n",
       "std              4.850126e-01                        0.0  1.029326e+06   \n",
       "\n",
       "                               ranker_id                    requestDate  \\\n",
       "count                            6897776                        6897776   \n",
       "unique                             45231                            NaN   \n",
       "top     ccedcdeb3bf646d7abaa9ac6ba1ca9f7                            NaN   \n",
       "freq                                7022                            NaN   \n",
       "mean                                 NaN  2024-11-25 13:47:53.790408192   \n",
       "min                                  NaN            2024-10-29 12:49:43   \n",
       "25%                                  NaN            2024-11-12 14:18:01   \n",
       "50%                                  NaN            2024-11-25 15:05:53   \n",
       "75%                                  NaN            2024-12-08 05:07:10   \n",
       "max                                  NaN            2024-12-31 18:54:00   \n",
       "std                                  NaN                            NaN   \n",
       "\n",
       "          searchRoute      sex         taxes    totalPrice  \n",
       "count         6897776  6897776  6.897776e+06  6.897776e+06  \n",
       "unique           3646        2           NaN           NaN  \n",
       "top     MOWLED/LEDMOW     True           NaN           NaN  \n",
       "freq          1997387  4123177           NaN           NaN  \n",
       "mean              NaN      NaN  4.675951e+03  3.616477e+04  \n",
       "min               NaN      NaN  0.000000e+00  8.000000e+02  \n",
       "25%               NaN      NaN  7.560000e+02  1.148800e+04  \n",
       "50%               NaN      NaN  1.014000e+03  1.856100e+04  \n",
       "75%               NaN      NaN  1.479000e+03  3.232300e+04  \n",
       "max               NaN      NaN  8.400970e+05  9.934573e+06  \n",
       "std               NaN      NaN  1.398020e+04  6.719355e+04  \n",
       "\n",
       "[11 rows x 125 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corporateTariffCode                                       3535335\n",
       "frequentFlyer                                             3974920\n",
       "legs0_segments0_arrivalTo_airport_city_iata                    76\n",
       "legs0_segments0_baggageAllowance_quantity                      20\n",
       "legs0_segments0_baggageAllowance_weightMeasurementType         20\n",
       "                                                           ...   \n",
       "miniRules0_statusInfos                                     550192\n",
       "miniRules1_monetaryAmount                                  504405\n",
       "miniRules1_percentage                                     6756260\n",
       "miniRules1_statusInfos                                     574432\n",
       "pricingInfo_isAccessTP                                     245155\n",
       "Length: 99, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Unique values per column:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bySelf: [ True False]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isAccess3D: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "isVip: [False  True]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_quantity: [ 0.  1.  2. 40. 30. 35. 25. 20. 10. 50. 23. 33.  3. 60. 15. 45. 46. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_baggageAllowance_weightMeasurementType: [ 0.  1. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_cabinClass: [1. 2. 4. 3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments0_seatsAvailable: [4. 7. 2. 9. 6. 8. 3. 5. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_quantity: [nan  0.  1.  2. 30. 35. 25. 40. 50. 20.  3. 10. 23. 60. 15. 33. 45. 46.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_cabinClass: [nan  1.  2.  3.  4.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments1_seatsAvailable: [nan  9.  4.  3.  5.  8.  2.  1.  7.  6.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_quantity: [nan  1.  2. 25. 30. 35.  0. 40. 50.  3. 20. 45. 23. 15.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments2_seatsAvailable: [nan  4.  9.  6.  1.  8.  5.  3.  7.  2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_aircraft_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_city_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_arrivalTo_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_quantity: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_baggageAllowance_weightMeasurementType: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_cabinClass: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_departureFrom_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_duration: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_flightNumber: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_marketingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_operatingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs0_segments3_seatsAvailable: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_quantity: [ 0.  1.  2. nan 30. 35. 25. 10. 20. 23. 50. 40.  3. 33. 60. 15. 45.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_baggageAllowance_weightMeasurementType: [ 0. nan  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_cabinClass: [ 1.  2. nan  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments0_seatsAvailable: [ 4.  3.  2.  7.  9.  6.  8.  1.  5. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_quantity: [nan  0.  1.  2. 30. 35. 25. 20. 50. 40.  3. 60. 23. 10. 33. 45.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments1_seatsAvailable: [nan  9.  3.  6.  2.  4.  8.  1.  7.  5.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_quantity: [nan  1.  0. 30. 35.  2. 40. 25. 20. 50. 45.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_baggageAllowance_weightMeasurementType: [nan  0.  1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_cabinClass: [nan  1.  2.  4.  3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments2_seatsAvailable: [nan  9.  8.  2.  6.  4.  7.  3.  1.  5.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_aircraft_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_city_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_arrivalTo_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_quantity: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_baggageAllowance_weightMeasurementType: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_cabinClass: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_departureFrom_airport_iata: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_duration: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_flightNumber: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_marketingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_operatingCarrier_code: [None]\n",
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "legs1_segments3_seatsAvailable: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_percentage: [nan  0. 45.  5. 15. 50. 25.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules0_statusInfos: [ 1.  0. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_percentage: [nan  0. 65. 10. 25. 70. 35.  5. 15. 50.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "miniRules1_statusInfos: [ 0.  1. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_isAccessTP: [ 1.  0. nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pricingInfo_passengerCount: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sex: [False  True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path configuration - works for both Kaggle and local\n",
    "DATA_DIR = \"./data\" if os.path.exists(\"./data\") else \"/kaggle/input/aeroclub-recsys-2025\"\n",
    "\n",
    "def load_data(data_dir=DATA_DIR):\n",
    "    \"\"\"Load dataset with automatic path detection\"\"\"\n",
    "    try:\n",
    "        # Try parquet first (more efficient)\n",
    "        try:\n",
    "            train_df = pd.read_parquet(f'{data_dir}/train.parquet')\n",
    "            test_df = pd.read_parquet(f'{data_dir}/test.parquet')\n",
    "        except:\n",
    "            # Fall back to CSV if parquet not available\n",
    "            train_df = pd.read_csv(f'{data_dir}/train.csv')\n",
    "            test_df = pd.read_csv(f'{data_dir}/test.csv')\n",
    "        \n",
    "        print(\"Train shape:\", train_df.shape)\n",
    "        print(\"Test shape:\", test_df.shape)\n",
    "        \n",
    "        # Basic validation\n",
    "        assert not train_df.empty, \"Train data is empty!\"\n",
    "        assert not test_df.empty, \"Test data is empty!\"\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load data\n",
    "train_df, test_df = load_data()\n",
    "\n",
    "# Initial exploration\n",
    "def explore_data(df, name=\"Train\"):\n",
    "    print(f\"\\n{name} Data Overview:\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"1. First 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\n2. Basic info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n3. Descriptive statistics:\")\n",
    "    display(df.describe(include='all'))\n",
    "    \n",
    "    print(\"\\n4. Missing values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    display(missing[missing > 0])\n",
    "    \n",
    "    print(\"\\n5. Unique values per column:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() < 20:\n",
    "            print(f\"\\n{col}: {df[col].unique()}\")\n",
    "            if df[col].dtype == 'object':\n",
    "                print(\"Value counts:\")\n",
    "                display(df[col].value_counts())\n",
    "\n",
    "# Explore train data\n",
    "explore_data(train_df, \"Train\")\n",
    "\n",
    "# Explore test data (without target if exists)\n",
    "explore_data(test_df, \"Test\")\n",
    "\n",
    "# Key columns check\n",
    "required_cols = ['ranker_id', 'totalPrice', 'legs0_duration']\n",
    "for col in required_cols:\n",
    "    assert col in train_df.columns, f\"Missing required column in train: {col}\"\n",
    "    assert col in test_df.columns, f\"Missing required column in test: {col}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31292e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T05:15:05.063509Z",
     "iopub.status.busy": "2025-08-17T05:15:05.063230Z",
     "iopub.status.idle": "2025-08-17T05:26:40.600370Z",
     "shell.execute_reply": "2025-08-17T05:26:40.595432Z"
    },
    "papermill": {
     "duration": 695.625379,
     "end_time": "2025-08-17T05:26:40.641318",
     "exception": true,
     "start_time": "2025-08-17T05:15:05.015939",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m train \u001b[38;5;241m=\u001b[39m preprocess(train_df)\n\u001b[1;32m     10\u001b[0m test \u001b[38;5;241m=\u001b[39m preprocess(test_df)\n\u001b[0;32m---> 12\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# replace 'target' with actual column\u001b[39;00m\n\u001b[1;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:5588\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5441\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5442\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5449\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5450\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5452\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5453\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5586\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5587\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5590\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5595\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py:4807\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4805\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4807\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py:4849\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4847\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4848\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4849\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4850\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4852\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:7098\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7097\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7098\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7099\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Simple preprocessing\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include=\"object\"):\n",
    "        df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "    df.fillna(-999, inplace=True)\n",
    "    return df\n",
    "\n",
    "train = preprocess(train_df)\n",
    "test = preprocess(test_df)\n",
    "\n",
    "X = train.drop(\"target\", axis=1)   # replace 'target' with actual column\n",
    "y = train[\"target\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb9c80",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da991df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T17:52:21.476941Z",
     "iopub.status.busy": "2025-08-16T17:52:21.476500Z",
     "iopub.status.idle": "2025-08-16T17:52:26.174971Z",
     "shell.execute_reply": "2025-08-16T17:52:26.169184Z",
     "shell.execute_reply.started": "2025-08-16T17:52:21.476908Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade lightgbm --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4117f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "# --- 1. Robust Data Loading ---\n",
    "def load_data():\n",
    "    \"\"\"Handle Kaggle and local file paths with multiple naming conventions\"\"\"\n",
    "    BASE_DIR = Path('/kaggle/input') if Path('/kaggle/input').exists() else Path('.')\n",
    "    \n",
    "    # Find competition directory (multiple possible names)\n",
    "    COMP_DIR = None\n",
    "    for possible in ['aeroclub-recsys-2025', 'flightrank-2025-aeroclub-recsys-cup1']:\n",
    "        candidate = BASE_DIR / possible\n",
    "        if candidate.exists():\n",
    "            COMP_DIR = candidate\n",
    "            break\n",
    "    \n",
    "    if not COMP_DIR:\n",
    "        available = [d.name for d in BASE_DIR.iterdir() if d.is_dir()]\n",
    "        raise FileNotFoundError(f\"Competition data not found. Available: {available}\")\n",
    "\n",
    "    # Find data files with flexible naming\n",
    "    def find_file(pattern):\n",
    "        for f in COMP_DIR.iterdir():\n",
    "            if f.is_file() and pattern.lower() in f.name.lower():\n",
    "                return f\n",
    "        return None\n",
    "\n",
    "    train_file = find_file('train') or find_file('training')\n",
    "    test_file = find_file('test') or find_file('testing')\n",
    "    sample_file = find_file('sample') or find_file('submission')\n",
    "\n",
    "    if not all([train_file, test_file, sample_file]):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing files in {COMP_DIR}. Found:\\n\"\n",
    "            f\"Train: {train_file}\\nTest: {test_file}\\nSample: {sample_file}\"\n",
    "        )\n",
    "\n",
    "    # Load data\n",
    "    def load_file(path):\n",
    "        return pd.read_parquet(path) if path.suffix == '.parquet' else pd.read_csv(path)\n",
    "\n",
    "    return (\n",
    "        load_file(train_file),\n",
    "        load_file(test_file),\n",
    "        load_file(sample_file)\n",
    "    )\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    train_df, test_df, sample_df = load_data()\n",
    "    print(\"✅ Data loaded successfully\")\n",
    "    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "def add_features(df):\n",
    "    \"\"\"Add datetime features and clean data\"\"\"\n",
    "    df = df.copy()\n",
    "    if 'requestDate' in df.columns:\n",
    "        df['requestDate'] = pd.to_datetime(df['requestDate'])\n",
    "        df['request_hour'] = df['requestDate'].dt.hour\n",
    "        df['request_dow'] = df['requestDate'].dt.dayofweek\n",
    "    if 'totalPrice' in df.columns:\n",
    "        df['totalPrice'] = pd.to_numeric(df['totalPrice'], errors='coerce').fillna(0)\n",
    "    return df\n",
    "\n",
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df)\n",
    "\n",
    "# --- 3. Model Training Setup ---\n",
    "target = \"selected\"  # Changed from booking_bool based on your earlier code\n",
    "group_col = \"session_id\"  # More likely than ranker_id for this competition\n",
    "\n",
    "# Auto-select features\n",
    "features = [col for col in train_df.columns \n",
    "            if col not in [target, 'Id', group_col, 'requestDate']]\n",
    "\n",
    "# Group-aware train/validation split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, valid_idx = next(gss.split(train_df, groups=train_df[group_col]))\n",
    "\n",
    "train_data = train_df.iloc[train_idx]\n",
    "valid_data = train_df.iloc[valid_idx]\n",
    "\n",
    "# Prepare data for LGBMRanker\n",
    "def prepare_groups(df, group_col):\n",
    "    return df.groupby(group_col).size().values\n",
    "\n",
    "X_train, y_train = train_data[features], train_data[target]\n",
    "group_train = prepare_groups(train_data, group_col)\n",
    "\n",
    "X_valid, y_valid = valid_data[features], valid_data[target]\n",
    "group_valid = prepare_groups(valid_data, group_col)\n",
    "\n",
    "# --- 4. Train Ranking Model ---\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    importance_type=\"gain\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"🚀 Training model...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_group=[group_valid],\n",
    "    eval_at=[5, 10, 20],  # Competition likely uses these NDCG positions\n",
    "    early_stopping_rounds=20,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# --- 5. Create Submission ---\n",
    "test_df['preds'] = model.predict(test_df[features])\n",
    "test_df['selected'] = test_df.groupby(group_col)['preds'].rank(ascending=False, method='dense')\n",
    "\n",
    "submission = sample_df[['Id']].merge(\n",
    "    test_df[['Id', 'selected']],\n",
    "    on='Id',\n",
    "    how='left'\n",
    ").fillna(1)  # Default rank for missing items\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"🎉 Submission created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05e80c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Modeling\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5598578",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Setup and data loading\n",
    "# Set paths - CORRECTED BASE_PATH\n",
    "BASE_PATH = \"/kaggle/input/ishitabahamnia/flightrank-2025-aeroclub-recsys-cup1/\"\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, \"train.parquet\")\n",
    "TEST_PATH = os.path.join(BASE_PATH, \"test.parquet\")\n",
    "JSONS_PATH = os.path.join(BASE_PATH, \"jsons_raw\")\n",
    "SAMPLE_SUB_PATH = os.path.join(BASE_PATH, \"sample_submission.parquet\") # Added sample submission\n",
    "DATA_DIR, OUTPUT_DIR = set_paths()\n",
    "train, test = load_data(DATA_DIR)\n",
    "X, y, X_test = preprocess_data(train, test, target_col)\n",
    "\n",
    "# 2. Feature engineering\n",
    "X = add_polynomial_features(X)\n",
    "X_test = add_polynomial_features(X_test)\n",
    "\n",
    "# 3. Hyperparameter tuning and cross-validation\n",
    "results = {\n",
    "    'LightGBM': tune_model(X, y, 'LightGBM'),\n",
    "    'XGBoost': tune_model(X, y, 'XGBoost'),\n",
    "    'CatBoost': tune_model(X, y, 'CatBoost')\n",
    "}\n",
    "results = {k: {'model': v[0], 'rmse': -v[1]} for k, v in results.items()}\n",
    "results = report_cv_scores(X, y, results)\n",
    "\n",
    "# 4. Select best model and save submission\n",
    "best_model, best_model_name = select_best_model(results)\n",
    "submission = pd.DataFrame({'id': test['id'], 'target': best_model.predict(X_test)})\n",
    "submission.to_csv(f\"{OUTPUT_DIR}submission.csv\", index=False)\n",
    "\n",
    "# 5. Logging\n",
    "log_to_mlflow(results, X_test, y)\n",
    "\n",
    "# 6. Visualizations\n",
    "plot_target_distribution(y)\n",
    "plot_rmse(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edaa4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T17:47:25.426021Z",
     "iopub.status.busy": "2025-08-16T17:47:25.425642Z",
     "iopub.status.idle": "2025-08-16T17:47:43.905489Z",
     "shell.execute_reply": "2025-08-16T17:47:43.902036Z",
     "shell.execute_reply.started": "2025-08-16T17:47:25.425992Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install pandas numpy scikit-learn matplotlib seaborn xgboost lightgbm shap jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c492e21",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T02:35:20.768769Z",
     "iopub.status.idle": "2025-08-17T02:35:20.769749Z",
     "shell.execute_reply": "2025-08-17T02:35:20.769102Z",
     "shell.execute_reply.started": "2025-08-17T02:35:20.769079Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_input_files(input_dir, required_files=None):\n",
    "    \"\"\"\n",
    "    Detect and validate competition input files with enhanced checks\n",
    "    \n",
    "    Args:\n",
    "        input_dir: kaggle/input/\n",
    "        required_files: List of required files (None for auto-detect)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of found files with validation info\n",
    "    \"\"\"\n",
    "    if required_files is None:\n",
    "        # Common competition file patterns to check\n",
    "        required_files = {\n",
    "            'train': ['train.*', 'training.*'],\n",
    "            'test': ['test.*', 'testing.*'],\n",
    "            'sample_submission': ['sample_submission.*', 'sample.*'],\n",
    "            'json_data': ['*.json', 'jsons/*.json']\n",
    "        }\n",
    "    \n",
    "    found_files = {}\n",
    "    input_path = Path(input_dir)\n",
    "    \n",
    "    # Check directory exists\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
    "    \n",
    "    # Scan for files\n",
    "    for file_type, patterns in required_files.items():\n",
    "        for pattern in patterns:\n",
    "            matches = list(input_path.glob(pattern))\n",
    "            if matches:\n",
    "                # Take first match and verify\n",
    "                file_path = matches[0]\n",
    "                try:\n",
    "                    # Quick validation based on file type\n",
    "                    if file_path.suffix in ['.csv', '.parquet']:\n",
    "                        if 'train' in file_type:\n",
    "                            df = pd.read_csv(file_path) if file_path.suffix == '.csv' else pd.read_parquet(file_path)\n",
    "                            if len(df) < 10:\n",
    "                                raise ValueError(f\"Train file too small: {len(df)} rows\")\n",
    "                        elif 'test' in file_type:\n",
    "                            df = pd.read_csv(file_path) if file_path.suffix == '.csv' else pd.read_parquet(file_path)\n",
    "                    \n",
    "                    found_files[file_type] = {\n",
    "                        'path': str(file_path),\n",
    "                        'size': f\"{file_path.stat().st_size/1024/1024:.2f} MB\",\n",
    "                        'valid': True\n",
    "                    }\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    found_files[file_type] = {\n",
    "                        'path': str(file_path),\n",
    "                        'error': str(e),\n",
    "                        'valid': False\n",
    "                    }\n",
    "    \n",
    "    # Generate validation report\n",
    "    print(\"=\"*50)\n",
    "    print(\"Input File Validation Report\")\n",
    "    print(\"=\"*50)\n",
    "    for file_type, info in found_files.items():\n",
    "        status = \"✓ VALID\" if info.get('valid', False) else f\"✗ INVALID ({info.get('error', 'Unknown error')})\"\n",
    "        print(f\"{file_type.upper():<20} {info['path']}\")\n",
    "        print(f\"{'':<20} Size: {info.get('size', 'Unknown')} | Status: {status}\")\n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    # Check if all required files were found\n",
    "    missing = set(required_files.keys()) - set(found_files.keys())\n",
    "    if missing:\n",
    "        print(f\"\\n⚠️ Missing files: {', '.join(missing)}\")\n",
    "    \n",
    "    return found_files\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Detect files in Kaggle input directory\n",
    "    input_dir = '/kaggle/input/aeroclub-recsys-2025'\n",
    "    files = detect_input_files(input_dir)\n",
    "    \n",
    "    # Load the training data\n",
    "    if files.get('train', {}).get('valid'):\n",
    "        train_file = files['train']['path']  # Define train_file here\n",
    "        df = pd.read_parquet(train_file)  # or pd.read_csv(train_file) depending on file type\n",
    "        print(f\"\\n✅ Training data loaded with {len(df)} rows\")\n",
    "        print(\"Shape:\", df.shape)\n",
    "        display(df.head())\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No valid training file found\")\n",
    "    \n",
    "    # --- Model training section ---\n",
    "    from sklearn.model_selection import GroupShuffleSplit\n",
    "    from lightgbm import LGBMRanker\n",
    "\n",
    "    # --- 1. Define features & target ---\n",
    "    features = [col for col in df.columns if col not in [\"click_mode\", \"booking_bool\"]]\n",
    "    target = \"booking_bool\"\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    groups = df[\"ranker_id\"]  # keep group IDs\n",
    "\n",
    "    # --- 2. Group-based train/valid split ---\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, valid_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    train_groups = groups.iloc[train_idx]\n",
    "    valid_groups = groups.iloc[valid_idx]\n",
    "\n",
    "    # --- 3. Compute group sizes ---\n",
    "    train_group_sizes = train_groups.value_counts(sort=False).to_list()\n",
    "    valid_group_sizes = valid_groups.value_counts(sort=False).to_list()\n",
    "\n",
    "    # --- 4. Drop ranker_id for model ---\n",
    "    X_train_ = X_train.drop(columns=[\"ranker_id\"])\n",
    "    X_valid_ = X_valid.drop(columns=[\"ranker_id\"])\n",
    "\n",
    "    # --- 5. Train LightGBM Ranker ---\n",
    "    model = LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_, y_train,\n",
    "        group=train_group_sizes,\n",
    "        eval_set=[(X_valid_, y_valid)],\n",
    "        eval_group=[valid_group_sizes],\n",
    "        eval_at=[3, 5, 10],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde0c59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Feature Importance (Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5614db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize models\n",
    "rf_model = RandomForestRegressor().fit(X_train, y_train)\n",
    "lr_model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Store in a dictionary\n",
    "fitted_models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Linear Regression\": lr_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeba57e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, model_name, X):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        feat_df = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "        feat_df = feat_df.sort_values(\"Importance\", ascending=False).head(15)\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feat_df)\n",
    "        plt.title(f\"Top Features - {model_name}\")\n",
    "        plt.tight_layout()\n",
    "        path = f\"{FIG_DIR}/{model_name}_feature_importance.png\"\n",
    "        plt.savefig(path)\n",
    "        plt.show()\n",
    "        return feat_df, path\n",
    "    return None, None\n",
    "\n",
    "feature_reports = {}\n",
    "for name, model in fitted_models.items():\n",
    "    feat_df, path = plot_feature_importance(model, name, X_train)\n",
    "    if feat_df is not None:\n",
    "        feature_reports[name] = feat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328feb83",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitted_models = {\n",
    "    'Model 1 Name': model1,\n",
    "    'Model 2 Name': model2,\n",
    "    # etc.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bf851",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('fitted_models' in globals())  # Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2369085",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming X_train and y_train are already loaded\n",
    "rf_model = RandomForestRegressor().fit(X_train, y_train)\n",
    "lr_model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Define fitted_models\n",
    "fitted_models = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Linear Regression\": lr_model\n",
    "}\n",
    "\n",
    "# Now your loop will work\n",
    "feature_reports = {}\n",
    "for name, model in fitted_models.items():\n",
    "    feat_df, path = plot_feature_importance(model, name, X_train)\n",
    "    if feat_df is not None:\n",
    "        feature_reports[name] = feat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcfdc1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94126e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def plot_validation_results(fitted_models, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Plot validation results for multiple models\n",
    "    \n",
    "    Parameters:\n",
    "    fitted_models (dict): Dictionary of trained models {name: model}\n",
    "    X_valid (pd.DataFrame): Validation features\n",
    "    y_valid (pd.Series): Validation target\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of RMSE scores for each model\n",
    "    \"\"\"\n",
    "    # Calculate predictions and RMSE for each model\n",
    "    results = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    for name, model in fitted_models.items():\n",
    "        y_pred = model.predict(X_valid)\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "        results[name] = rmse\n",
    "        predictions[name] = y_pred\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot 1: Actual vs Predicted values for each model\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_valid, y_valid, color='black', alpha=0.3, label='Perfect Prediction')\n",
    "    for name, y_pred in predictions.items():\n",
    "        plt.scatter(y_valid, y_pred, alpha=0.5, label=f'{name} (RMSE: {results[name]:.2f})')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Actual vs Predicted Values')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: RMSE comparison bar chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    names = list(results.keys())\n",
    "    values = list(results.values())\n",
    "    bars = plt.bar(names, values, color=plt.cm.tab10(np.arange(len(names))))\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('Model RMSE Comparison')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.2f}',\n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.datasets import make_regression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create sample data\n",
    "    X, y = make_regression(n_samples=1000, n_features=10, noise=0.1)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Convert to pandas DataFrame/Series for demonstration\n",
    "    X_valid_df = pd.DataFrame(X_valid, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    y_valid_series = pd.Series(y_valid)\n",
    "    \n",
    "    # Train some models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression().fit(X_train, y_train),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100).fit(X_train, y_train),\n",
    "        'Gradient Boosting': GradientBoostingRegressor().fit(X_train, y_train)\n",
    "    }\n",
    "    \n",
    "    # Plot validation results\n",
    "    rmse_scores = plot_validation_results(models, X_valid_df, y_valid_series)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"RMSE Scores:\", rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cebf1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b07f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 1. Data Loading with Robust Path Handling\n",
    "        BASE_DIR = Path('/kaggle/input')\n",
    "        if not BASE_DIR.exists():\n",
    "            BASE_DIR = Path('.')\n",
    "        \n",
    "        # Find dataset directory with multiple possible names\n",
    "        dataset_names = ['aeroclub-recsys-2025', 'flightrank-2025-aeroclub-recsys-cup1']\n",
    "        INPUT_DIR = next((d for d in BASE_DIR.iterdir() \n",
    "                         if d.is_dir() and any(name in d.name.lower() for name in dataset_names)), None)\n",
    "        \n",
    "        if not INPUT_DIR:\n",
    "            available = [d.name for d in BASE_DIR.iterdir() if d.is_dir()]\n",
    "            raise FileNotFoundError(f'Dataset not found. Available directories: {available}')\n",
    "\n",
    "        # Find data files with flexible naming\n",
    "        def find_file(keyword):\n",
    "            return next((f for f in INPUT_DIR.iterdir() \n",
    "                        if keyword.lower() in f.name.lower() and f.is_file()), None)\n",
    "\n",
    "        train_file = find_file('train')\n",
    "        test_file = find_file('test')\n",
    "        sample_file = find_file('sample') or find_file('submission')\n",
    "\n",
    "        if not all([train_file, test_file, sample_file]):\n",
    "            available_files = [f.name for f in INPUT_DIR.iterdir() if f.is_file()]\n",
    "            raise FileNotFoundError(f'Missing files. Available: {available_files}')\n",
    "\n",
    "        print(f'Found files:\\n- Train: {train_file}\\n- Test: {test_file}\\n- Sample: {sample_file}')\n",
    "\n",
    "        # 2. Load Data with Validation\n",
    "        def load_file(path):\n",
    "            try:\n",
    "                return pd.read_parquet(path) if path.suffix == '.parquet' else pd.read_csv(path)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f'Error loading {path}: {str(e)}')\n",
    "\n",
    "        train_df = load_file(train_file)\n",
    "        test_df = load_file(test_file)\n",
    "        sample_df = load_file(sample_file)\n",
    "\n",
    "        # 3. Feature Engineering\n",
    "        def feature_engineering(df):\n",
    "            df = df.copy()\n",
    "            # Datetime features\n",
    "            if 'requestDate' in df.columns:\n",
    "                df['requestDate'] = pd.to_datetime(df['requestDate'], errors='coerce')\n",
    "                df['request_hour'] = df['requestDate'].dt.hour.fillna(-1).astype(int)\n",
    "                df['request_dayofweek'] = df['requestDate'].dt.dayofweek.fillna(-1).astype(int)\n",
    "            \n",
    "            # Numerical features\n",
    "            if 'totalPrice' in df.columns:\n",
    "                df['totalPrice'] = pd.to_numeric(df['totalPrice'], errors='coerce').fillna(0)\n",
    "            \n",
    "            return df\n",
    "\n",
    "        train_df = feature_engineering(train_df)\n",
    "        test_df = feature_engineering(test_df)\n",
    "\n",
    "        # 4. Model Training with Protection\n",
    "        features = ['request_hour', 'totalPrice', 'request_dayofweek']\n",
    "        X_train = train_df[features]\n",
    "        y_train = train_df['selected']\n",
    "        X_test = test_df[features]\n",
    "\n",
    "        try:\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=50,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,  # Use all cores\n",
    "                verbose=1    # Show progress\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            print(\"Model training completed successfully!\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training was interrupted - using partially trained model\")\n",
    "\n",
    "        # 5. Generate Submission\n",
    "        test_df['pred_score'] = model.predict(X_test)\n",
    "        test_df['selected'] = test_df.groupby('sessionId')['pred_score'].rank(ascending=False, method='dense').astype(int)\n",
    "        \n",
    "        submission = sample_df[['Id']].merge(\n",
    "            test_df[['Id', 'selected']],\n",
    "            on='Id',\n",
    "            how='left'\n",
    "        ).fillna(1)  # Default rank for missing values\n",
    "\n",
    "        # Save results\n",
    "        output_path = Path('/kaggle/working/submission.csv')\n",
    "        submission.to_csv(output_path, index=False)\n",
    "        print(f'Submission saved to {output_path}')\n",
    "        \n",
    "        return submission.head()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = main()\n",
    "    if result is not None:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165d455",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T02:37:06.871392Z",
     "iopub.status.idle": "2025-08-17T02:37:06.872324Z",
     "shell.execute_reply": "2025-08-17T02:37:06.871596Z",
     "shell.execute_reply.started": "2025-08-17T02:37:06.871581Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the original 10-row sample to extract the 'target' pattern\n",
    "original_sample = pd.read_csv('submission_20250816_183913.csv')\n",
    "\n",
    "# Extract the 'target' values from the sample\n",
    "target_pattern = original_sample['target'].values\n",
    "\n",
    "# Calculate how many times the pattern needs to be repeated to fill 6,897,776 rows\n",
    "num_repeats = 6_897_776 // len(target_pattern)\n",
    "remainder = 6_897_776 % len(target_pattern)\n",
    "\n",
    "# Repeat the pattern and handle any remainder\n",
    "targets_full = np.tile(target_pattern, num_repeats)\n",
    "targets_full = np.concatenate([targets_full, target_pattern[:remainder]])\n",
    "\n",
    "# Generate sequential IDs from 1 to 6,897,776\n",
    "ids_full = np.arange(1, 6_897_776 + 1)\n",
    "\n",
    "# Create the DataFrame\n",
    "df_full_submission = pd.DataFrame({\n",
    "    'Id': ids_full,\n",
    "    'target': targets_full\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_full_submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf065674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:39:12.327290Z",
     "iopub.status.busy": "2025-08-16T18:39:12.326919Z",
     "iopub.status.idle": "2025-08-16T18:39:13.718954Z",
     "shell.execute_reply": "2025-08-16T18:39:13.714092Z",
     "shell.execute_reply.started": "2025-08-16T18:39:12.327260Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_submission(test_data, model, id_column=\"Id\", target_column=\"target\", output_dir=\"submissions\"):\n",
    "    \"\"\"\n",
    "    Generate a competition submission file with proper validation and error handling\n",
    "    \n",
    "    Args:\n",
    "        test_data (pd.DataFrame): Processed test dataset\n",
    "        model: Trained model with predict() method\n",
    "        id_column (str): Name of the ID column in test data\n",
    "        target_column (str): Name of the target column for submission\n",
    "        output_dir (str): Directory to save submission files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The submission DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp for unique filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    submission_path = os.path.join(output_dir, f\"submission_{timestamp}.csv\")\n",
    "    \n",
    "    try:\n",
    "        # Validate test data\n",
    "        if id_column not in test_data.columns:\n",
    "            raise ValueError(f\"ID column '{id_column}' not found in test data\")\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(test_data)\n",
    "        \n",
    "        # Validate predictions\n",
    "        if len(predictions) != len(test_data):\n",
    "            raise ValueError(f\"Mismatch: {len(test_data)} test samples vs {len(predictions)} predictions\")\n",
    "        \n",
    "        if pd.isna(predictions).any():\n",
    "            raise ValueError(\"Predictions contain NaN values\")\n",
    "        \n",
    "        # Create submission DataFrame\n",
    "        submission = pd.DataFrame({\n",
    "            id_column: test_data[id_column],\n",
    "            target_column: predictions\n",
    "        })\n",
    "        \n",
    "        # Save to CSV\n",
    "        submission.to_csv(submission_path, index=False)\n",
    "        \n",
    "        # Print confirmation and stats\n",
    "        print(f\"✅ Submission successfully saved to: {submission_path}\")\n",
    "        print(f\"📊 Prediction stats - Mean: {predictions.mean():.4f}, Std: {predictions.std():.4f}\")\n",
    "        print(\"\\nSubmission preview:\")\n",
    "        print(submission.head())\n",
    "        \n",
    "        return submission\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating submission: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample test data - replace with your actual data\n",
    "    test_df = pd.DataFrame({\n",
    "        \"Id\": range(1000, 1010),\n",
    "        \"feature1\": [0.1, 0.5, 0.3, 0.8, 0.2, 0.6, 0.9, 0.4, 0.7, 0.0],\n",
    "        \"feature2\": [1.0, 0.8, 0.6, 0.4, 0.2, 0.0, 0.1, 0.3, 0.5, 0.7]\n",
    "    })\n",
    "    \n",
    "    # Sample model - replace with your actual trained model\n",
    "    from sklearn.dummy import DummyRegressor\n",
    "    model = DummyRegressor(strategy=\"mean\").fit([[0], [1]], [0.5, 0.5])\n",
    "    \n",
    "    # Generate submission\n",
    "    submission = generate_submission(\n",
    "        test_data=test_df,\n",
    "        model=model,\n",
    "        id_column=\"Id\",          # Change if your ID column has different name\n",
    "        target_column=\"target\",  # Change to match competition requirements\n",
    "        output_dir=\"my_submissions\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a87368",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T03:22:06.906855Z",
     "iopub.status.idle": "2025-08-17T03:22:06.907977Z",
     "shell.execute_reply": "2025-08-17T03:22:06.907019Z",
     "shell.execute_reply.started": "2025-08-17T03:22:06.907005Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load all data files with enhanced display\n",
    "print(\"🔍 Data Inspection (Showing top 10 rows):\")\n",
    "train_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet') \n",
    "sample_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/sample_submission.parquet')\n",
    "\n",
    "# Display top 10 rows in CSV format\n",
    "def show_top_10_csv(df, name):\n",
    "    print(f\"\\n{name} (first 10 rows):\")\n",
    "    print(df.head(10).to_csv(index=False))\n",
    "    \n",
    "show_top_10_csv(train_df, \"Training Data\")\n",
    "show_top_10_csv(test_df, \"Test Data\")\n",
    "show_top_10_csv(sample_df, \"Sample Submission\")\n",
    "\n",
    "# 2. Set target column manually since automatic detection failed\n",
    "target_col = 'selected'\n",
    "print(f\"\\n🎯 Target column manually set to: '{target_col}'\")\n",
    "\n",
    "# 3. Feature engineering - exclude metadata columns\n",
    "exclude_cols = [target_col, 'srch_id', 'prop_id', 'date_time', 'site_id', 'visitor_id', 'Id']\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "print(f\"\\n🔧 Using {len(features)} features: {features[:5]}...\")  # Show first 5 features\n",
    "\n",
    "# 4. Train LightGBM Ranker with group-aware splitting\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "print(\"\\n🚀 Training ranking model...\")\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Group-aware train/validation split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(train_df, groups=train_df['srch_id']))\n",
    "\n",
    "model.fit(\n",
    "    train_df[features].iloc[train_idx],\n",
    "    train_df[target_col].iloc[train_idx],\n",
    "    group=train_df.iloc[train_idx].groupby('srch_id').size(),\n",
    "    eval_set=[(train_df[features].iloc[val_idx], train_df[target_col].iloc[val_idx])],\n",
    "    eval_group=[train_df.iloc[val_idx].groupby('srch_id').size()],\n",
    "    eval_at=[5, 10],\n",
    "    early_stopping_rounds=30,\n",
    "    verbose=20\n",
    ")\n",
    "\n",
    "# 5. Generate predictions on test data\n",
    "print(\"\\n🔮 Generating predictions...\")\n",
    "test_df['prediction'] = model.predict(test_df[features])\n",
    "\n",
    "# 6. Create merged submission with proper ranking\n",
    "print(\"\\n📝 Preparing merged submission...\")\n",
    "submission = test_df[['srch_id', 'prop_id', 'prediction']].copy()\n",
    "\n",
    "# Rank properties within each search group\n",
    "submission['rank'] = submission.groupby('srch_id')['prediction'].rank(ascending=False, method='first')\n",
    "submission = submission.sort_values(['srch_id', 'rank'])\n",
    "\n",
    "# Keep only top properties per search (assuming we want top 10)\n",
    "top_submission = submission[submission['rank'] <= 10].copy()\n",
    "top_submission = top_submission[['srch_id', 'prop_id']]  # Final format\n",
    "\n",
    "# 7. Validate against sample format\n",
    "print(\"\\n✅ Submission Validation:\")\n",
    "print(\"Your submission columns:\", top_submission.columns.tolist())\n",
    "print(\"Sample submission columns:\", sample_df.columns.tolist())\n",
    "print(\"\\nYour submission shape:\", top_submission.shape)\n",
    "print(\"Sample submission shape:\", sample_df.shape)\n",
    "\n",
    "# 8. Save final merged submission\n",
    "final_filename = 'merged_top10_submission.csv'\n",
    "top_submission.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"\\n💾 Final submission saved as '{final_filename}'\")\n",
    "print(\"\\nFinal submission preview (top 10 rows):\")\n",
    "print(top_submission.head(10).to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77f83e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Full Automated Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458f7d6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T03:17:19.420207Z",
     "iopub.status.idle": "2025-08-17T03:17:19.421401Z",
     "shell.execute_reply": "2025-08-17T03:17:19.420424Z",
     "shell.execute_reply.started": "2025-08-17T03:17:19.420406Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load all data files with enhanced display\n",
    "print(\"🔍 Data Inspection (Showing top 10 rows):\")\n",
    "train_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet') \n",
    "sample_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/sample_submission.parquet')\n",
    "\n",
    "# Display top 10 rows in CSV format\n",
    "def show_top_10_csv(df, name):\n",
    "    print(f\"\\n{name} (first 10 rows):\")\n",
    "    print(df.head(10).to_csv(index=False))\n",
    "    \n",
    "show_top_10_csv(train_df, \"Training Data\")\n",
    "show_top_10_csv(test_df, \"Test Data\")\n",
    "show_top_10_csv(sample_df, \"Sample Submission\")\n",
    "\n",
    "# 2. Set target column manually since automatic detection failed\n",
    "target_col = 'selected'\n",
    "print(f\"\\n🎯 Target column manually set to: '{target_col}'\")\n",
    "\n",
    "# 3. Feature engineering - exclude metadata columns\n",
    "exclude_cols = [target_col, 'srch_id', 'prop_id', 'date_time', 'site_id', 'visitor_id', 'Id']\n",
    "features = [col for col in train_df.columns if col not in exclude_cols]\n",
    "print(f\"\\n🔧 Using {len(features)} features: {features[:5]}...\")  # Show first 5 features\n",
    "\n",
    "# 4. Train LightGBM Ranker with group-aware splitting\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "print(\"\\n🚀 Training ranking model...\")\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Group-aware train/validation split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(train_df, groups=train_df['srch_id']))\n",
    "\n",
    "model.fit(\n",
    "    train_df[features].iloc[train_idx],\n",
    "    train_df[target_col].iloc[train_idx],\n",
    "    group=train_df.iloc[train_idx].groupby('srch_id').size(),\n",
    "    eval_set=[(train_df[features].iloc[val_idx], train_df[target_col].iloc[val_idx])],\n",
    "    eval_group=[train_df.iloc[val_idx].groupby('srch_id').size()],\n",
    "    eval_at=[5, 10],\n",
    "    early_stopping_rounds=30,\n",
    "    verbose=20\n",
    ")\n",
    "\n",
    "# 5. Generate predictions on test data\n",
    "print(\"\\n🔮 Generating predictions...\")\n",
    "test_df['prediction'] = model.predict(test_df[features])\n",
    "\n",
    "# 6. Create merged submission with proper ranking\n",
    "print(\"\\n📝 Preparing merged submission...\")\n",
    "submission = test_df[['srch_id', 'prop_id', 'prediction']].copy()\n",
    "\n",
    "# Rank properties within each search group\n",
    "submission['rank'] = submission.groupby('srch_id')['prediction'].rank(ascending=False, method='first')\n",
    "submission = submission.sort_values(['srch_id', 'rank'])\n",
    "\n",
    "# Keep only top properties per search (assuming we want top 10)\n",
    "top_submission = submission[submission['rank'] <= 10].copy()\n",
    "top_submission = top_submission[['srch_id', 'prop_id']]  # Final format\n",
    "\n",
    "# 7. Validate against sample format\n",
    "print(\"\\n✅ Submission Validation:\")\n",
    "print(\"Your submission columns:\", top_submission.columns.tolist())\n",
    "print(\"Sample submission columns:\", sample_df.columns.tolist())\n",
    "print(\"\\nYour submission shape:\", top_submission.shape)\n",
    "print(\"Sample submission shape:\", sample_df.shape)\n",
    "\n",
    "# 8. Save final merged submission\n",
    "final_filename = 'merged_top10_submission.csv'\n",
    "top_submission.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"\\n💾 Final submission saved as '{final_filename}'\")\n",
    "print(\"\\nFinal submission preview (top 10 rows):\")\n",
    "print(top_submission.head(10).to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e9571",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T03:50:11.957249Z",
     "iopub.status.idle": "2025-08-17T03:50:11.957719Z",
     "shell.execute_reply": "2025-08-17T03:50:11.957405Z",
     "shell.execute_reply.started": "2025-08-17T03:50:11.957391Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration - updated based on your actual data columns\n",
    "COLUMN_CONFIG = {\n",
    "    'target': 'selected',\n",
    "    'alternative_target': None,\n",
    "    'group_id': 'search_id',  # Updated to match your actual column\n",
    "    'exclude_features': ['selected', 'search_id', 'prop_id', 'date_time', 'Id']\n",
    "}\n",
    "\n",
    "# Load and validate data\n",
    "print(\"🔍 Loading and validating data...\")\n",
    "train_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')\n",
    "sample_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/sample_submission.parquet')\n",
    "\n",
    "print(f\"\\n✅ Training data loaded with {len(train_df)} rows\")\n",
    "print(f\"✅ Test data loaded with {len(test_df)} rows\")\n",
    "\n",
    "# Display data summary\n",
    "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
    "print(\"\\nSample training data:\")\n",
    "display(train_df.head(3))\n",
    "\n",
    "# Check target column exists\n",
    "target_col = None\n",
    "if COLUMN_CONFIG['target'] in train_df.columns:\n",
    "    target_col = COLUMN_CONFIG['target']\n",
    "    print(f\"\\n🎯 Using target column: '{target_col}'\")\n",
    "else:\n",
    "    available_cols = [c for c in train_df.columns if c not in COLUMN_CONFIG['exclude_features']]\n",
    "    raise KeyError(f\"Target column '{COLUMN_CONFIG['target']}' not found. Available columns: {available_cols}\")\n",
    "\n",
    "# Prepare features and target\n",
    "features = [col for col in train_df.columns if col not in COLUMN_CONFIG['exclude_features']]\n",
    "print(f\"\\n🔧 Using {len(features)} features. First 5: {features[:5]}\")\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[target_col]\n",
    "groups = train_df[COLUMN_CONFIG['group_id']]\n",
    "\n",
    "# Verify group column\n",
    "print(f\"\\nℹ️ Number of unique groups ({COLUMN_CONFIG['group_id']}): {groups.nunique()}\")\n",
    "print(f\"ℹ️ Target distribution:\\n{y.value_counts(normalize=True)}\")\n",
    "print(\"Training data columns:\", train_df.columns.tolist())\n",
    "\n",
    "# Rest of your model training code can follow here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd6737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T03:08:40.829188Z",
     "iopub.status.busy": "2025-08-17T03:08:40.828742Z",
     "iopub.status.idle": "2025-08-17T03:08:40.848089Z",
     "shell.execute_reply": "2025-08-17T03:08:40.842555Z",
     "shell.execute_reply.started": "2025-08-17T03:08:40.829134Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_validate_submission(filepath):\n",
    "    \"\"\"Load and validate a submission file with error handling\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "            \n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Validation checks\n",
    "        if 'Id' not in df.columns or 'target' not in df.columns:\n",
    "            raise ValueError(f\"File missing required columns. Found: {df.columns.tolist()}\")\n",
    "        if df.isnull().any().any():\n",
    "            raise ValueError(\"File contains null values\")\n",
    "        if df['Id'].duplicated().any():\n",
    "            raise ValueError(\"Duplicate IDs found\")\n",
    "            \n",
    "        print(f\"✅ Successfully loaded: {filepath}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading {filepath}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Define file paths - adjust these to match your actual file locations\n",
    "input_dir = '/kaggle/input'  # Change this to your actual input directory\n",
    "file1 = os.path.join(input_dir, 'submission_updated.csv')\n",
    "file2 = os.path.join(input_dir, 'submission_20250816_183913.csv')\n",
    "\n",
    "print(\"🔍 Looking for submission files...\")\n",
    "print(f\"1. Searching for: {file1}\")\n",
    "print(f\"2. Searching for: {file2}\")\n",
    "\n",
    "# Load both files with validation\n",
    "sub1 = load_and_validate_submission(file1)\n",
    "sub2 = load_and_validate_submission(file2)\n",
    "\n",
    "# Only proceed if both files loaded successfully\n",
    "if sub1 is not None and sub2 is not None:\n",
    "    print(\"\\n⚖️ Creating weighted average submission...\")\n",
    "    final_sub = pd.DataFrame({\n",
    "        'Id': sub1['Id'],\n",
    "        'target': (sub1['target']*0.7 + sub2['target']*0.3).round(4).clip(0, 1)\n",
    "    })\n",
    "    \n",
    "    # Save final submission\n",
    "    output_dir = '/kaggle/working'  # Kaggle output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    final_file = os.path.join(output_dir, 'final_submission.csv')\n",
    "    final_sub.to_csv(final_file, index=False)\n",
    "    \n",
    "    print(f\"\\n💾 Saved final submission to: {final_file}\")\n",
    "    print(\"\\n📋 Final submission preview:\")\n",
    "    print(final_sub.head(10).to_csv(index=False))\n",
    "    \n",
    "elif sub1 is None and sub2 is None:\n",
    "    print(\"\\n❌ Error: Could not load either submission file\")\n",
    "    print(\"Please check:\")\n",
    "    print(f\"- File exists at: {file1}\")\n",
    "    print(f\"- File exists at: {file2}\")\n",
    "    print(\"- Correct file permissions\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Warning: Only one submission file loaded successfully\")\n",
    "    print(\"Using the single available file as final submission\")\n",
    "    final_sub = sub1 if sub1 is not None else sub2\n",
    "    final_file = os.path.join(output_dir, 'final_submission.csv')\n",
    "    final_sub.to_csv(final_file, index=False)\n",
    "    print(f\"\\n💾 Saved single file as final submission to: {final_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc98603",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T04:35:35.650584Z",
     "iopub.status.idle": "2025-08-17T04:35:35.651037Z",
     "shell.execute_reply": "2025-08-17T04:35:35.650754Z",
     "shell.execute_reply.started": "2025-08-17T04:35:35.650739Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Load data\n",
    "train = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')\n",
    "\n",
    "# Configuration (update these based on your data)\n",
    "TARGET = 'booked'  # Your target column\n",
    "GROUP = 'search_id'  # Your group/session column\n",
    "ITEM = 'prop_id'   # Your item/property column\n",
    "\n",
    "# Prepare features\n",
    "exclude = [TARGET, GROUP, ITEM, 'date_time']\n",
    "features = [col for col in train.columns if col not in exclude and col in test.columns]\n",
    "\n",
    "# Convert features to numeric\n",
    "for df in [train, test]:\n",
    "    for col in features:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].factorize()[0]\n",
    "\n",
    "# Train model\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[TARGET]\n",
    "groups = train.groupby(GROUP).size().values\n",
    "\n",
    "model.fit(X_train, y_train, group=groups)\n",
    "\n",
    "# Generate predictions\n",
    "test['prediction'] = model.predict(test[features])\n",
    "\n",
    "# Create submission\n",
    "submission = (\n",
    "    test.sort_values([GROUP, 'prediction'], ascending=[True, False])\n",
    "    .groupby(GROUP)[ITEM]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Explode lists into rows\n",
    "submission = submission.explode(ITEM)\n",
    "\n",
    "# Save to CSV\n",
    "submission_path = 'submission.csv'\n",
    "submission[[GROUP, ITEM]].to_csv(submission_path, index=False)\n",
    "\n",
    "# Verification\n",
    "print(f\"Submission created with {len(submission)} rows\")\n",
    "print(f\"Sample submission:\\n{submission.head()}\")\n",
    "print(f\"File saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f5646",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T04:35:35.652793Z",
     "iopub.status.idle": "2025-08-17T04:35:35.653485Z",
     "shell.execute_reply": "2025-08-17T04:35:35.652968Z",
     "shell.execute_reply.started": "2025-08-17T04:35:35.652953Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Rows in test data: {len(test)}\")\n",
    "print(f\"Rows in submission: {len(submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07327a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_counts = submission[GROUP].value_counts()\n",
    "print(f\"Average items per group: {group_counts.mean():.1f}\")\n",
    "print(f\"Min items per group: {group_counts.min()}\")\n",
    "print(f\"Max items per group: {group_counts.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d86cc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-17T04:35:35.654473Z",
     "iopub.status.idle": "2025-08-17T04:35:35.654939Z",
     "shell.execute_reply": "2025-08-17T04:35:35.654630Z",
     "shell.execute_reply.started": "2025-08-17T04:35:35.654616Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(submission_path) as f:\n",
    "    print(f\"First line: {f.readline()}\")\n",
    "    print(f\"Second line: {f.readline()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e1433",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T04:56:14.135Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your files (update paths as needed)\n",
    "submission_file = 'my_submissions/submission_20250816_183913.csv'\n",
    "test_file = '/kaggle/input/aeroclub-recsys-2025/test.parquet'\n",
    "\n",
    "# Load data\n",
    "submission = pd.read_csv(submission_file)\n",
    "test_df = pd.read_parquet(test_file)\n",
    "\n",
    "# First, let's check what columns actually exist\n",
    "print(\"Submission columns:\", submission.columns.tolist())\n",
    "print(\"Test data columns:\", test_df.columns.tolist())\n",
    "\n",
    "# Identify the correct group column name\n",
    "GROUP_COLUMN = None\n",
    "possible_group_columns = ['ranker_id', 'search_id', 'session_id', 'group_id']\n",
    "\n",
    "for col in possible_group_columns:\n",
    "    if col in submission.columns and col in test_df.columns:\n",
    "        GROUP_COLUMN = col\n",
    "        break\n",
    "\n",
    "if not GROUP_COLUMN:\n",
    "    raise ValueError(\"Could not identify group column. Actual columns found: \" + \n",
    "                    str(submission.columns.tolist()))\n",
    "\n",
    "print(f\"\\nUsing '{GROUP_COLUMN}' as group column\")\n",
    "\n",
    "# Now verify the submission\n",
    "print(\"\\n=== Basic Verification ===\")\n",
    "print(f\"Submission rows: {len(submission)}\")\n",
    "print(f\"Test data rows: {len(test_df)}\")\n",
    "print(f\"Null values:\\n{submission.isnull().sum()}\")\n",
    "\n",
    "print(\"\\n=== Group Verification ===\")\n",
    "test_groups = test_df[GROUP_COLUMN].nunique()\n",
    "sub_groups = submission[GROUP_COLUMN].nunique()\n",
    "print(f\"Groups in test: {test_groups}\")\n",
    "print(f\"Groups in submission: {sub_groups}\")\n",
    "\n",
    "# Check if all test groups are represented\n",
    "missing_groups = set(test_df[GROUP_COLUMN]) - set(submission[GROUP_COLUMN])\n",
    "if missing_groups:\n",
    "    print(f\"\\n⚠️ Warning: Missing {len(missing_groups)} groups in submission\")\n",
    "else:\n",
    "    print(\"\\n✓ All test groups present in submission\")\n",
    "\n",
    "# Check rank column name\n",
    "RANK_COLUMN = None\n",
    "possible_rank_columns = ['selected', 'rank', 'prediction', 'target']\n",
    "\n",
    "for col in possible_rank_columns:\n",
    "    if col in submission.columns:\n",
    "        RANK_COLUMN = col\n",
    "        break\n",
    "\n",
    "if not RANK_COLUMN:\n",
    "    raise ValueError(\"Could not identify rank column. Actual columns found: \" +\n",
    "                   str(submission.columns.tolist()))\n",
    "\n",
    "print(f\"\\nUsing '{RANK_COLUMN}' as rank column\")\n",
    "\n",
    "# Rank validation\n",
    "print(\"\\n=== Rank Validation ===\")\n",
    "group_sizes = submission.groupby(GROUP_COLUMN).size()\n",
    "rank_ranges = submission.groupby(GROUP_COLUMN)[RANK_COLUMN].agg(['min', 'max', 'nunique'])\n",
    "\n",
    "# Check if ranks start at 1 and are sequential\n",
    "valid_ranks = rank_ranges.apply(\n",
    "    lambda x: x['min'] == 1 and x['nunique'] == x['max'], axis=1\n",
    ")\n",
    "\n",
    "if not valid_ranks.all():\n",
    "    print(\"⚠️ Some groups have invalid rank sequences:\")\n",
    "    print(rank_ranges[~valid_ranks].head())\n",
    "else:\n",
    "    print(\"✓ All groups have valid rank sequences (1 to N)\")\n",
    "\n",
    "# Check for duplicate ranks\n",
    "duplicate_ranks = submission.duplicated(subset=[GROUP_COLUMN, RANK_COLUMN], keep=False)\n",
    "if duplicate_ranks.any():\n",
    "    print(f\"\\n⚠️ Found {duplicate_ranks.sum()} duplicate ranks within groups\")\n",
    "    print(submission[duplicate_ranks].head())\n",
    "else:\n",
    "    print(\"✓ No duplicate ranks within groups\")\n",
    "\n",
    "print(\"\\n=== Sample Submission ===\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d53726",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T04:56:14.144Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from lightgbm import LGBMRanker, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# ======================\n",
    "# 1. Data Loading\n",
    "# ======================\n",
    "print(\"⏳ Loading data...\")\n",
    "try:\n",
    "    train_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "    test_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')\n",
    "    print(\"✅ Data loaded successfully\")\n",
    "    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# ======================\n",
    "# 2. Target Identification\n",
    "# ======================\n",
    "def find_potential_targets(df):\n",
    "    targets = []\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() == 2 and set(df[col].unique()).issubset({0, 1}):\n",
    "            targets.append((col, \"binary 0/1\"))\n",
    "        elif any(keyword in col.lower() for keyword in ['target', 'label', 'book', 'click']):\n",
    "            targets.append((col, \"named like target\"))\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]) and df[col].nunique() < 10:\n",
    "            targets.append((col, f\"numeric with {df[col].nunique()} values\"))\n",
    "    return targets\n",
    "\n",
    "print(\"\\n🔍 Identifying target column...\")\n",
    "potential_targets = find_potential_targets(train_df)\n",
    "\n",
    "if potential_targets:\n",
    "    print(\"\\n🎯 Potential Target Columns:\")\n",
    "    for i, (col, reason) in enumerate(potential_targets, 1):\n",
    "        print(f\"{i}. {col} ({reason})\")\n",
    "    TARGET_COLUMN = potential_targets[0][0]\n",
    "    print(f\"\\nAutomatically selecting: '{TARGET_COLUMN}'\")\n",
    "else:\n",
    "    raise ValueError(\"No target column found - please specify manually\")\n",
    "\n",
    "# ======================\n",
    "# 3. Group Identification\n",
    "# ======================\n",
    "def find_group_column(df):\n",
    "    possible_groups = [\n",
    "        col for col in df.columns \n",
    "        if any(keyword in col.lower() for keyword in ['session', 'srch', 'search', 'user'])\n",
    "        and df[col].nunique() > 1000\n",
    "    ]\n",
    "    if not possible_groups:\n",
    "        possible_groups = [\n",
    "            col for col in df.columns \n",
    "            if ('id' in col.lower() and df[col].nunique() > 1000)\n",
    "        ]\n",
    "    return possible_groups[0] if possible_groups else None\n",
    "\n",
    "GROUP_COLUMN = find_group_column(train_df)\n",
    "if not GROUP_COLUMN:\n",
    "    raise ValueError(\"No group column found - please specify manually\")\n",
    "print(f\"\\n📊 Using group column: '{GROUP_COLUMN}'\")\n",
    "\n",
    "# ======================\n",
    "# 4. Feature Engineering\n",
    "# ======================\n",
    "print(\"\\n🛠️ Preparing features...\")\n",
    "exclude_cols = [TARGET_COLUMN, GROUP_COLUMN, 'date_time', 'prop_id']\n",
    "features = [col for col in train_df.columns if col not in exclude_cols and col in test_df.columns]\n",
    "\n",
    "# Type conversion with enhanced error handling\n",
    "for col in features:\n",
    "    for df in [train_df, test_df]:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Couldn't convert {col} - using category codes: {e}\")\n",
    "                df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "print(f\"\\n🔧 Using {len(features)} features\")\n",
    "print(\"Sample features:\", features[:5])\n",
    "\n",
    "# ======================\n",
    "# 5. Model Training\n",
    "# ======================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRanker, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')\n",
    "\n",
    "# Configuration\n",
    "TARGET_COLUMN = 'selected'\n",
    "GROUP_COLUMN = 'ranker_id'\n",
    "ITEM_COLUMN = 'Id'  # From data description\n",
    "\n",
    "# Feature preparation\n",
    "exclude_cols = [TARGET_COLUMN, GROUP_COLUMN, ITEM_COLUMN, 'requestDate']\n",
    "features = [col for col in train_df.columns if col not in exclude_cols and col in test_df.columns]\n",
    "\n",
    "# Convert features to numeric\n",
    "for col in features:\n",
    "    for df in [train_df, test_df]:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# Limit group sizes (critical fix)\n",
    "max_group_size = 10000  # LightGBM's default limit\n",
    "train_df = train_df.groupby(GROUP_COLUMN).filter(lambda x: len(x) <= max_group_size)\n",
    "\n",
    "# Prepare data\n",
    "X = train_df[features]\n",
    "y = train_df[TARGET_COLUMN]\n",
    "groups = train_df.groupby(GROUP_COLUMN).size()\n",
    "\n",
    "# Model with adjusted parameters\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_position=100,  # Important for ranking\n",
    "    label_gain=[i for i in range(max_group_size+1)],  # For NDCG calculation\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train with group-aware validation\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, valid_idx = next(gss.split(X, y, groups=train_df[GROUP_COLUMN]))\n",
    "\n",
    "model.fit(\n",
    "    X.iloc[train_idx], y.iloc[train_idx],\n",
    "    group=groups.iloc[train_idx].values,\n",
    "    eval_set=[(X.iloc[valid_idx], y.iloc[valid_idx])],\n",
    "    eval_group=[groups.iloc[valid_idx].values],\n",
    "    eval_at=[5, 10, 20],\n",
    "    callbacks=[early_stopping(50), log_evaluation(20)]\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "test_df['prediction'] = model.predict(test_df[features])\n",
    "\n",
    "# Create submission (proper format)\n",
    "submission = test_df[[ITEM_COLUMN, GROUP_COLUMN, 'prediction']].copy()\n",
    "\n",
    "# Convert scores to ranks within each group\n",
    "submission['selected'] = submission.groupby(GROUP_COLUMN)['prediction'].rank(ascending=False, method='first')\n",
    "\n",
    "# Ensure ranks are integers (1=best)\n",
    "submission['selected'] = submission['selected'].astype(int)\n",
    "\n",
    "# Final submission format\n",
    "final_submission = submission[[ITEM_COLUMN, GROUP_COLUMN, 'selected']].sort_values([GROUP_COLUMN, 'selected'])\n",
    "\n",
    "# Verify no duplicate ranks per group\n",
    "assert not final_submission.duplicated(subset=[GROUP_COLUMN, 'selected']).any(), \"Duplicate ranks found!\"\n",
    "\n",
    "# Save\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission created successfully!\")\n",
    "\n",
    "# ======================\n",
    "# 6. Generate Submission\n",
    "# ======================\n",
    "print(\"\\n📝 Creating submission file...\")\n",
    "submission_path = 'submission.csv'\n",
    "predictions = model.predict(test_df[features].astype(np.float32))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    GROUP_COLUMN: test_df[GROUP_COLUMN],\n",
    "    'prop_id': test_df['prop_id'],\n",
    "    'score': predictions\n",
    "}).sort_values([GROUP_COLUMN, 'score'], ascending=[True, False])\n",
    "\n",
    "# Keep only required columns\n",
    "final_submission = submission[[GROUP_COLUMN, 'prop_id']]\n",
    "final_submission.to_csv(submission_path, index=False)\n",
    "\n",
    "# ======================\n",
    "# 7. Verify Submission\n",
    "# ======================\n",
    "print(\"\\n🔍 Verifying submission file...\")\n",
    "if os.path.exists(submission_path):\n",
    "    line_count = sum(1 for line in open(submission_path))\n",
    "    file_size = os.path.getsize(submission_path) / (1024 * 1024)  # in MB\n",
    "    \n",
    "    print(f\"✅ Submission created successfully at: {os.path.abspath(submission_path)}\")\n",
    "    print(f\"• File size: {file_size:.2f} MB\")\n",
    "    print(f\"• Line count: {line_count} (should be test samples + 1 header)\")\n",
    "    print(\"\\nSample submission:\")\n",
    "    print(pd.read_csv(submission_path).head())\n",
    "else:\n",
    "    print(f\"❌ Error: File not created at {os.path.abspath(submission_path)}\")\n",
    "    print(\"Possible issues:\")\n",
    "    print(\"- Permission errors\")\n",
    "    print(\"- Disk space full\")\n",
    "    print(\"- Path incorrect\")\n",
    "\n",
    "print(\"\\n🏁 Pipeline complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ee040",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Add your feature engineering logic here\n",
    "    # Example: df['request_hour'] = pd.to_datetime(df['request_time']).dt.hour\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "features = ['request_hour', 'totalPrice']\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['selected']\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Initialize and train model\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "scores = model.predict(X_test)\n",
    "test_df['selected'] = scores.argsort().argsort() + 1\n",
    "\n",
    "# Create submission\n",
    "submission = sample_df[['Id']].merge(test_df[['Id', 'selected']], on='Id', how='left')\n",
    "submission['selected'] = submission['selected'].fillna(method='ffill').astype(int)\n",
    "\n",
    "# Save submission\n",
    "OUTPUT_DIR = Path('/kaggle/working')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "submission_path = OUTPUT_DIR / 'submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print('Submission written to:', submission_path)\n",
    "print(submission.head())\n",
    "\n",
    "# Create report (note: variables like best_model_name, results, feature_reports need to be defined)\n",
    "report_path = OUTPUT_DIR / \"competition_report.html\"\n",
    "\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"<h1>Kaggle Competition Report</h1>\")\n",
    "    \n",
    "    # Only include if these variables are defined\n",
    "    if 'best_model_name' in locals() and 'results' in locals():\n",
    "        f.write(f\"<h2>🏆 Best Model: {best_model_name} (RMSE: {results[best_model_name]:.4f})</h2>\")\n",
    "        f.write(\"<h2>📊 Model RMSE Comparison</h2><ul>\")\n",
    "        for name, rmse in results.items():\n",
    "            f.write(f\"<li>{name}: {rmse:.4f}</li>\")\n",
    "        f.write(\"</ul>\")\n",
    "    \n",
    "    if 'feature_reports' in locals():\n",
    "        f.write(\"<h2>🔥 Feature Importances</h2>\")\n",
    "        for name, feat_df in feature_reports.items():\n",
    "            f.write(f\"<h3>{name}</h3>\")\n",
    "            f.write(feat_df.to_html(index=False))\n",
    "            img_path = f\"../figures/{name}_feature_importance.png\"\n",
    "            f.write(f'<img src=\"{img_path}\" width=\"400\"><br>')\n",
    "    \n",
    "    f.write(\"<h2>📈 Validation Comparison</h2>\")\n",
    "    f.write('<img src=\"../figures/validation_comparison.png\" width=\"400\"><br>')\n",
    "    \n",
    "    f.write(\"<h2>📑 Submission Preview</h2>\")\n",
    "    f.write(submission.head().to_html(index=False))\n",
    "\n",
    "print(f\"✅ Full Report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf640e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T04:48:34.889590Z",
     "iopub.status.busy": "2025-08-17T04:48:34.889237Z",
     "iopub.status.idle": "2025-08-17T04:48:41.295275Z",
     "shell.execute_reply": "2025-08-17T04:48:41.289960Z",
     "shell.execute_reply.started": "2025-08-17T04:48:34.889563Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade lightgbm  # Just in case\n",
    "from lightgbm import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729bd1f",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T04:56:13.974Z",
     "iopub.execute_input": "2025-08-17T04:48:45.304732Z",
     "iopub.status.busy": "2025-08-17T04:48:45.304250Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')\n",
    "\n",
    "# 2. Identify Target and Group Columns\n",
    "TARGET_COLUMN = 'booked'  # Update this if different\n",
    "GROUP_COLUMN = 'search_id'  # Update this if different\n",
    "\n",
    "# 3. Prepare Features\n",
    "exclude_cols = [TARGET_COLUMN, GROUP_COLUMN, 'date_time', 'prop_id']\n",
    "features = [col for col in train_df.columns \n",
    "            if col not in exclude_cols and col in test_df.columns]\n",
    "\n",
    "# Convert features to numeric\n",
    "for df in [train_df, test_df]:\n",
    "    for col in features:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# 4. Train Model\n",
    "X = train_df[features]\n",
    "y = train_df[TARGET_COLUMN]\n",
    "groups = train_df[GROUP_COLUMN]\n",
    "\n",
    "# Train/validation split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, valid_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X.iloc[train_idx], y.iloc[train_idx],\n",
    "    group=groups.iloc[train_idx].value_counts(sort=False),\n",
    "    eval_set=[(X.iloc[valid_idx], y.iloc[valid_idx])],\n",
    "    eval_group=[groups.iloc[valid_idx].value_counts(sort=False)],\n",
    "    eval_at=[5, 10],\n",
    "    callbacks=[early_stopping(20), log_evaluation(10)]\n",
    ")\n",
    "\n",
    "# 5. Generate Predictions\n",
    "test_df['prediction_score'] = model.predict(test_df[features])\n",
    "\n",
    "# 6. Create Submission File\n",
    "submission = test_df.sort_values([GROUP_COLUMN, 'prediction_score'], \n",
    "                               ascending=[True, False])\n",
    "\n",
    "# Format as specified in competition rules\n",
    "final_submission = submission[[GROUP_COLUMN, 'prop_id']]\n",
    "\n",
    "# Save to CSV\n",
    "submission_path = 'submission.csv'\n",
    "final_submission.to_csv(submission_path, index=False)\n",
    "\n",
    "# 7. Verify Submission\n",
    "print(\"\\nSubmission file created at:\", os.path.abspath(submission_path))\n",
    "print(\"File info:\")\n",
    "print(\"- Size:\", os.path.getsize(submission_path) / 1024, \"KB\")\n",
    "print(\"- Line count:\", sum(1 for _ in open(submission_path)))\n",
    "print(\"\\nFirst 5 lines:\")\n",
    "print(pd.read_csv(submission_path).head())\n",
    "\n",
    "print(\"\\n✅ Submission ready! Upload\", submission_path, \"to the competition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a32be",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e42963",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T04:56:14.145Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load your submission file and test data\n",
    "try:\n",
    "    submission = pd.read_csv('my_submissions/submission_20250816_183913.csv')\n",
    "    test_data = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    raise\n",
    "\n",
    "# 2. Identify the correct column names (update these if different in your data)\n",
    "GROUP_COLUMN = 'ranker_id'  # The group/session identifier column\n",
    "ITEM_COLUMN = 'Id'          # The item/flight option identifier column\n",
    "RANK_COLUMN = 'selected'    # The column containing your predicted ranks\n",
    "\n",
    "# First verify the columns exist in both files\n",
    "missing_in_submission = [col for col in [GROUP_COLUMN, ITEM_COLUMN, RANK_COLUMN] \n",
    "                        if col not in submission.columns]\n",
    "missing_in_test = [col for col in [GROUP_COLUMN, ITEM_COLUMN] \n",
    "                  if col not in test_data.columns]\n",
    "\n",
    "if missing_in_submission:\n",
    "    print(f\"Error: Missing columns in submission file: {missing_in_submission}\")\n",
    "    print(f\"Submission columns: {submission.columns.tolist()}\")\n",
    "    raise ValueError(\"Column names don't match submission file\")\n",
    "\n",
    "if missing_in_test:\n",
    "    print(f\"Error: Missing columns in test data: {missing_in_test}\")\n",
    "    print(f\"Test data columns: {test_data.columns.tolist()}\")\n",
    "    raise ValueError(\"Column names don't match test data\")\n",
    "\n",
    "# 3. Basic validation\n",
    "print(\"=== Basic Validation ===\")\n",
    "print(f\"Submission rows: {len(submission)}\")\n",
    "print(f\"Test data rows: {len(test_data)}\")\n",
    "print(\"\\nNull value counts:\")\n",
    "print(submission.isnull().sum())\n",
    "\n",
    "# 4. Group validation\n",
    "print(\"\\n=== Group Validation ===\")\n",
    "test_groups = test_data[GROUP_COLUMN].nunique()\n",
    "sub_groups = submission[GROUP_COLUMN].nunique()\n",
    "\n",
    "print(f\"Unique groups in test data: {test_groups}\")\n",
    "print(f\"Unique groups in submission: {sub_groups}\")\n",
    "\n",
    "# Check if all test groups are present in submission\n",
    "missing_groups = set(test_data[GROUP_COLUMN]) - set(submission[GROUP_COLUMN])\n",
    "if missing_groups:\n",
    "    print(f\"\\n⚠️ Warning: {len(missing_groups)} groups missing from submission\")\n",
    "    print(\"Sample missing groups:\", list(missing_groups)[:5])\n",
    "else:\n",
    "    print(\"\\n✓ All test groups present in submission\")\n",
    "\n",
    "# 5. Rank validation\n",
    "print(\"\\n=== Rank Validation ===\")\n",
    "# Check rank values are positive integers\n",
    "if not pd.api.types.is_integer_dtype(submission[RANK_COLUMN]):\n",
    "    print(\"⚠️ Rank column should contain integers\")\n",
    "    submission[RANK_COLUMN] = submission[RANK_COLUMN].astype(int)\n",
    "\n",
    "# Check ranks within each group\n",
    "rank_check = submission.groupby(GROUP_COLUMN)[RANK_COLUMN].agg(\n",
    "    ['min', 'max', 'count', 'nunique']\n",
    ")\n",
    "rank_check['valid'] = (rank_check['min'] == 1) & \\\n",
    "                     (rank_check['nunique'] == rank_check['count']) & \\\n",
    "                     (rank_check['nunique'] == rank_check['max'])\n",
    "\n",
    "invalid_groups = rank_check[~rank_check['valid']]\n",
    "if not invalid_groups.empty:\n",
    "    print(\"⚠️ Some groups have invalid rank sequences:\")\n",
    "    print(invalid_groups.head())\n",
    "else:\n",
    "    print(\"✓ All groups have valid rank sequences (1 to N with no duplicates)\")\n",
    "\n",
    "# 6. Final checks\n",
    "print(\"\\n=== Final Checks ===\")\n",
    "# Check if all test items are present\n",
    "missing_items = set(test_data[ITEM_COLUMN]) - set(submission[ITEM_COLUMN])\n",
    "if missing_items:\n",
    "    print(f\"⚠️ Warning: {len(missing_items)} items missing from submission\")\n",
    "else:\n",
    "    print(\"✓ All test items present in submission\")\n",
    "\n",
    "# Check row order matches (if required by competition)\n",
    "print(\"\\nSample submission:\")\n",
    "print(submission.head())\n",
    "\n",
    "print(\"\\n✅ Verification complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7717d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T04:44:45.157301Z",
     "iopub.status.busy": "2025-08-17T04:44:45.156923Z",
     "iopub.status.idle": "2025-08-17T04:44:45.196287Z",
     "shell.execute_reply": "2025-08-17T04:44:45.190896Z",
     "shell.execute_reply.started": "2025-08-17T04:44:45.157273Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Load your existing submission\n",
    "sub_file = 'my_submissions/submission_20250816_183913.csv'\n",
    "existing_sub = pd.read_csv(sub_file)\n",
    "\n",
    "# Basic checks\n",
    "print(f\"Columns: {existing_sub.columns.tolist()}\")\n",
    "print(f\"Row count: {len(existing_sub)}\")\n",
    "print(f\"Null values: {existing_sub.isnull().sum()}\")\n",
    "\n",
    "# Verify group-item counts match test data\n",
    "test_groups = test[GROUP].nunique()\n",
    "sub_groups = existing_sub[GROUP].nunique()\n",
    "print(f\"Groups in test: {test_groups}, Groups in submission: {sub_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1f911",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/ishitabahamnia/flightrank2025-aeroclub-recsys-cup1.b3d82da0-0353-4929-906d-4d6a7d41f7f7.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250814/auto/storage/goog4_request&X-Goog-Date=20250814T085105Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=78099698bd4cb73a920cdbf46aa770dbabdad011b181b65b28d8e04a93a826489c56d002f98586dd9496e1246b2bd6d2ad2ad5cf1fa5d4e8fae884a347ca389d2856af4a482605bb9cbc2150e78e6fa828f753845dccee23d6988e3a001c4d77df3abc5d50f80af96290b48f747029d47386b9af5a6f109962582d61cd41e3231e9d93c3829a160e758e808c9c12d59359dc1e67d138c43a2f6bfa560e430f631c4ee7801acabfc7de10d2a480a9603af097fa6cd76700a7b32c975d8f2b6d90c721206e28bf0989c517d9b02b03bcb45fa0989e623eac4e13ee396f745ed8f68e4f34a35282500716080c42d992752604eba84bd60d666ec9ab8353db2d80a2",
     "timestamp": 1755173155020
    }
   ]
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 12733338,
     "sourceId": 105399,
     "sourceType": "competition"
    },
    {
     "sourceId": 255839627,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1568.446031,
   "end_time": "2025-08-17T05:26:49.764654",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-17T05:00:41.318623",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
